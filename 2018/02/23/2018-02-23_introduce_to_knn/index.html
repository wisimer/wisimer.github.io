<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>KNN 简介 | XP</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="一、前言k-近邻算法（kNN，k-NearestNeighbor），是一种监督分类算法，是最简单的机器学习分类算法之一。其核心思想在于用距离目标最近的 k 个样本数据的分类来代表目标的分类（这k个样本数据和目标数据最为相似）。kNN 是一种惰性学习方法。 k-近邻算法的缺点是对数据的局部结构非常敏感。">
<meta name="keywords" content="KNN">
<meta property="og:type" content="article">
<meta property="og:title" content="KNN 简介">
<meta property="og:url" content="http://ai.wisim.me/2018/02/23/2018-02-23_introduce_to_knn/index.html">
<meta property="og:site_name" content="XP">
<meta property="og:description" content="一、前言k-近邻算法（kNN，k-NearestNeighbor），是一种监督分类算法，是最简单的机器学习分类算法之一。其核心思想在于用距离目标最近的 k 个样本数据的分类来代表目标的分类（这k个样本数据和目标数据最为相似）。kNN 是一种惰性学习方法。 k-近邻算法的缺点是对数据的局部结构非常敏感。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-09-20T08:29:45.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="KNN 简介">
<meta name="twitter:description" content="一、前言k-近邻算法（kNN，k-NearestNeighbor），是一种监督分类算法，是最简单的机器学习分类算法之一。其核心思想在于用距离目标最近的 k 个样本数据的分类来代表目标的分类（这k个样本数据和目标数据最为相似）。kNN 是一种惰性学习方法。 k-近邻算法的缺点是对数据的局部结构非常敏感。">
    

    
        <link rel="alternate" href="/" title="XP" type="application/atom+xml" />
    

    
        <link rel="icon" href="https://github.com/wisimer/wisimer.github.io/blob/master/css/images/logo.png?raw=true" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?c87f7ac22d7007b78c0d4fa544da6c44";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    


</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">XP</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">HOME</a>
                
                    <a class="main-nav-link" href="/archives">ARCHIVE</a>
                
                    <a class="main-nav-link" href="/categories">CATEGOTY</a>
                
                    <a class="main-nav-link" href="/about">ABOUT</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">HOME</a></td>
                
                    <td><a class="main-nav-link" href="/archives">ARCHIVE</a></td>
                
                    <td><a class="main-nav-link" href="/categories">CATEGOTY</a></td>
                
                    <td><a class="main-nav-link" href="/about">ABOUT</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            <section id="main"><article id="post-2018-02-23_introduce_to_knn" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            KNN 简介
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2018/02/23/2018-02-23_introduce_to_knn/">
            <time datetime="2018-02-22T16:00:00.000Z" itemprop="datePublished">2018-02-23</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/ML/">ML</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/KNN/">KNN</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h4 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h4><p>k-近邻算法（kNN，k-NearestNeighbor），是一种<code>监督分类</code>算法，是最简单的机器学习分类算法之一。其核心思想在于用<code>距离目标最近的 k 个样本数据的分类</code>来代表目标的分类（这k个样本数据和目标数据最为相似）。kNN 是一种<code>惰性学习方法</code>。</p>
<p>k-近邻算法的缺点是对数据的<code>局部结构非常敏感</code>。</p>
<a id="more"></a>
<h4 id="二、算法描述"><a href="#二、算法描述" class="headerlink" title="二、算法描述"></a>二、算法描述</h4><h5 id="1-具体算法过程："><a href="#1-具体算法过程：" class="headerlink" title="1. 具体算法过程："></a>1. 具体算法过程：</h5><p>（1）. 计算分类未知数据 x_new 与训练样本集数据 x 的欧氏距离 distance</p>
<p>（2）. 将 distance 递增排序</p>
<p>（3）. 选取 distance 的前 k 个点</p>
<p>（4）. 选取前 k 个点中，出现频率最高的类别 y 作为 x_new的分类</p>
<h5 id="2-k-值得选择"><a href="#2-k-值得选择" class="headerlink" title="2. k 值得选择"></a>2. k 值得选择</h5><p>k 值的选择对 KNN 算法的性能有较大影响，选得太小容易欠拟合，选得太大容易过拟合。在实际应用中，一般选取一个区间，采用<code>交叉验证法</code>来选取最优的 k 值。</p>
<h5 id="3-KNN-分类决策规则"><a href="#3-KNN-分类决策规则" class="headerlink" title="3. KNN 分类决策规则"></a>3. KNN 分类决策规则</h5><p>由于 KNN 属于惰性学习算法，所以并不存在事先的训练过程，决策都是在预测时直接根据决策规则做出的。<code>KNN 分类的决策规则往往是多数表决</code>，也就是由输入实例的 k 个邻近的训练实例中的多数决定的。那么为什么多数表决规则可以作为 KNN 的决策规则呢？具体解释如下：</p>
<p>首先设 KNN 分类算法的分类函数是 f(x) ，损失函数是 0-1 损失函数，即：</p>
<script type="math/tex; mode=display">L(Y,f(X)) = \begin{cases}1, &Y\neq f(X) \\ 0, & Y=f(X)\end{cases}</script><p>那么误分类的概率是： $P(Y \neq f(X))=1-p(Y = f(X))$</p>
<p>对于某一个给定的实例 $x_i$，以及它的最邻近的 k 个训练实例构成集合 N。如果涵盖 N 的区域的类别是 $c_j$，那么误分类率是：</p>
<script type="math/tex; mode=display">\frac{1}{k}\sum_{x_i \in N}I(y_i \neq c_j)=1-\frac{1}{k}\sum_{x_i \in N}I(y_i = c_j)</script><p>这里的 <code>函数 I</code> 是<code>指示函数</code>，它是定义在某集合X上的函数，表示其中有哪些元素属于某一子集A。</p>
<blockquote>
<p>要使误分类率最小就是要使 $\sum_{x_i \in N}I(y_i = c_j)$ 最大，也就是在 N 集合中，属于类别 c 的实例个数越多越好。所以多数表决规则等价于经验风险最小化。</p>
</blockquote>
<h4 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a>三、代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    group = np.array([[<span class="number">1</span>, <span class="number">1.1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>]])</span><br><span class="line">    labels = [<span class="string">'A'</span>, <span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">定义knn算法分类器函数</span></span><br><span class="line"><span class="string">:param inX: 测试数据</span></span><br><span class="line"><span class="string">:param dataSet: 训练数据</span></span><br><span class="line"><span class="string">:param labels: 分类类别</span></span><br><span class="line"><span class="string">:param k: k值</span></span><br><span class="line"><span class="string">:return: 所属分类</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(inX, dataSet, labels, k)</span>:</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]  <span class="comment">#shape（m, n）m列n个特征</span></span><br><span class="line">    diffMat = np.tile(inX, (dataSetSize, <span class="number">1</span>)) - dataSet</span><br><span class="line">    sqDiffMat = diffMat ** <span class="number">2</span></span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>)</span><br><span class="line">    distances = sqDistances ** <span class="number">0.5</span>  <span class="comment">#欧式距离</span></span><br><span class="line">    sortedDistIndicies = distances.argsort()  <span class="comment">#排序并返回index</span></span><br><span class="line"></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]</span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span> <span class="comment">#default 0</span></span><br><span class="line"></span><br><span class="line">    sortedClassCount = sorted(classCount.items(), key=<span class="keyword">lambda</span> d:d[<span class="number">1</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dataSet, labels = createDataSet()</span><br><span class="line">    r = classify([<span class="number">0</span>, <span class="number">0.2</span>], dataSet, labels, <span class="number">3</span>)</span><br><span class="line">    print(r)</span><br></pre></td></tr></table></figure>
<p>输出 <code>B</code></p>
<h4 id="四、k-邻近法的特殊实现：kd-树"><a href="#四、k-邻近法的特殊实现：kd-树" class="headerlink" title="四、k 邻近法的特殊实现：kd 树"></a>四、k 邻近法的特殊实现：kd 树</h4><p>KNN 最简单地实现就是线性扫描，计算出训练集中每个点到输入实例的距离，再排序取前 k 个，采用多数表决判断输入实例的类别。但是当训练集很大时，这种方法的性能很差。为了提高 KNN 的性能，可以考虑使用特殊的存储结构，减少计算距离的次数，提高搜索效率。下面介绍一种 kd 树方法:</p>
<h5 id="1-kd-树的构造"><a href="#1-kd-树的构造" class="headerlink" title="1. kd 树的构造"></a>1. kd 树的构造</h5><p>kd 树是一种对 k 维空间中的实例进行存储以便快速检索的树形数据结构。kd 树是二叉树，表示对 k 维空间的不断划分。构造 kd 树相当于用垂直于坐标轴的超平面将 k 维空间划分为一系列 k 维超矩形区域。kd树的每一个节点对应于一个 k 维超矩形区域。kd 树的具体构造过程：</p>
<p>每次选出一个特征上的中位数(median)，将这个实例构造为 kd 树的一个节点，并对训练集进行切分。然后依次换一个特征，再取其中位数构造 kd 树节点。如此迭代，直到每个实例都被作为节点插入到 kd 树中。</p>
<p>之所要要选择中位数作为划分点，是因为这样构造出的 kd 树是平衡的。不过平衡的 kd 树搜索效率不一定是最高的。</p>
<h5 id="2-kd-树的搜索"><a href="#2-kd-树的搜索" class="headerlink" title="2. kd 树的搜索"></a>2. kd 树的搜索</h5><p>对于 KNN 算法，我们要找的是前 k 个距离最近的实例。这里使用 kd 树，先寻找最邻近节点。对于给定一个输入实例，先从 kd 树的根节点开始搜索，比较第一个特征，如果输入实例第一个特征值小于根节点的第一个特征值，则向左子树继续搜索，否则向右子树继续搜索。而继续搜索子树的时候，则要切换到下一个特征比较。最终到达某一个叶节点，这个叶节点就是要找的<code>最邻近节点</code>。如果 k&gt;1，则要继续寻找剩下的 k-1 个邻近点。这里比较重要了，继续寻找的时候，采用回溯的方法，从刚刚找到的那个节点回退到它的父节点，再寻找和输入实例最靠近的节点。如此迭代，直到找到 k 个邻近点结束。</p>
<p>如果训练样本是随进分布的，kd 树搜索的计算复杂度是 O(log N)。</p>
<hr>
<p>参考：</p>
<p>[1]. 《统计学习方法（李航）》：k 邻近法</p>
<p>[2]. <a href="https://www.cnblogs.com/eyeszjwang/articles/2429382.html" target="_blank" rel="noopener">k-d tree算法</a></p>
<p>[3]. <a href="https://www.youtube.com/watch?v=TLxWtXEbtFE" target="_blank" rel="noopener">KD tree algorithm</a></p>
<hr>
<p>THE END.</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">


    <div class="bdsharebuttonbox">
    <a href="#" class="bds_more" data-cmd="more">分享到：</a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间">QQ空间</a>
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博">新浪微博</a>
    <a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博">腾讯微博</a>
    <a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网">人人网</a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信">微信</a>
</div>
<script>
window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"share":{"bdSize":16}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>
<style>
    .bdshare_popup_box {
        border-radius: 4px;
        border: #e1e1e1 solid 1px;
    }
    .bdshare-button-style0-16 a,
    .bdshare-button-style0-16 .bds_more {
        padding-left: 20px;
        margin: 6px 10px 6px 0;
    }
    .bdshare_dialog_list a,
    .bdshare_popup_list a,
    .bdshare_popup_bottom a {
        font-family: 'Microsoft Yahei';
    }
    .bdshare_popup_top {
        display: none;
    }
    .bdshare_popup_bottom {
        height: auto;
        padding: 5px;
    }
</style>


</div>

            
    
        <a href="http://ai.wisim.me/2018/02/23/2018-02-23_introduce_to_knn/#comments" class="article-comment-link">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/02/24/2018-02-25_nltk/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    NLP基础
                
            </div>
        </a>
    
    
        <a href="/2018/02/19/2018-02-19_introduce_to_perceptron/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">感知机 简介</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div id="lv-container" data-id="city" data-uid=MTAyMC8zNDc5NS8xMTMzMg==></div>
</section>
    

</section>
            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2019 Wisimer<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        
    
    
    <!-- 来必力City版安装代码 -->
    <script type="text/javascript">
     (function(d, s) {
         var j, e = d.getElementsByTagName(s)[0];

         if (typeof LivereTower === 'function') { return; }

         j = d.createElement(s);
         j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
         j.async = true;

         e.parentNode.insertBefore(j, e);
     })(document, 'script');
    </script>
  <noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
  <!-- City版安装代码已完成 -->





    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>