<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>ML &amp; DL 课程搜集 | XP</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Video Book Site Blog">
<meta name="keywords" content="ML,DL">
<meta property="og:type" content="article">
<meta property="og:title" content="ML &amp; DL 课程搜集">
<meta property="og:url" content="http://ai.wisim.me/1970/01/03/2018-11-21-course/index.html">
<meta property="og:site_name" content="XP">
<meta property="og:description" content="Video Book Site Blog">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-11-21T14:00:25.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ML &amp; DL 课程搜集">
<meta name="twitter:description" content="Video Book Site Blog">
    

    
        <link rel="alternate" href="/" title="XP" type="application/atom+xml" />
    

    
        <link rel="icon" href="https://github.com/wisimer/wisimer.github.io/blob/master/css/images/logo.png?raw=true" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?c87f7ac22d7007b78c0d4fa544da6c44";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    


</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">XP</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">HOME</a>
                
                    <a class="main-nav-link" href="/archives">ARCHIVE</a>
                
                    <a class="main-nav-link" href="/categories">CATEGOTY</a>
                
                    <a class="main-nav-link" href="/about">ABOUT</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">HOME</a></td>
                
                    <td><a class="main-nav-link" href="/archives">ARCHIVE</a></td>
                
                    <td><a class="main-nav-link" href="/categories">CATEGOTY</a></td>
                
                    <td><a class="main-nav-link" href="/about">ABOUT</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            <section id="main"><article id="post-2018-11-21-course" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            ML &amp; DL 课程搜集
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/1970/01/03/2018-11-21-course/">
            <time datetime="1970-01-02T16:00:00.000Z" itemprop="datePublished">1970-01-03</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/ML/">ML</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/DL/">DL</a>, <a class="tag-link" href="/tags/ML/">ML</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <ul>
<li>Video</li>
<li>Book</li>
<li>Site</li>
<li>Blog</li>
</ul>
<a id="more"></a>
<h3 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h3><h4 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h4><ol>
<li>Machine Learing (Andew Ng)</li>
</ol>
<ul>
<li><a href="https://study.163.com/course/courseMain.htm?courseId=1004570029" target="_blank" rel="noopener">网易云课堂</a></li>
<li><a href="https://www.youtube.com/watch?v=PPLop4L2eGk&amp;list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN" target="_blank" rel="noopener">YouTube</a></li>
</ul>
<ol>
<li><p>Machine Learning (Hung-yi Lee, 李宏毅 , NTU) : <a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49" target="_blank" rel="noopener">YouTube</a></p>
</li>
<li><p>Machine Learning Foundations (機器學習基石，林轩田) : <a href="https://www.youtube.com/playlist?list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf" target="_blank" rel="noopener">YouTube</a></p>
</li>
</ol>
<ol>
<li>Machine Learning Techniques (機器學習技法，林轩田) : <a href="https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2" target="_blank" rel="noopener">YouTube</a></li>
<li><a href="https://www.edx.org/course/introduction-probability-science-mitx-6-041x-2" target="_blank" rel="noopener">Introduction to Probability - The Science of Uncertainty</a></li>
</ol>
<h4 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h4><ol>
<li>Deep Learing(Andrew Ng)</li>
</ol>
<ul>
<li><a href="https://study.163.com/provider/2001053000/index.htm" target="_blank" rel="noopener">网易云课堂</a></li>
<li><a href="https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w" target="_blank" rel="noopener">YouTube</a></li>
<li><a href="http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/?utm_source=com.ideashower.readitlater.pro&amp;utm_medium=social&amp;utm_oi=32948766113792" target="_blank" rel="noopener">Note</a></li>
</ul>
<ol>
<li><p>Stanford University CS231n, Spring 2017 (CV) : <a href="https://www.youtube.com/playlist?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk" target="_blank" rel="noopener">YouTube</a></p>
</li>
<li><p>Neural Networks for Machine Learning — Geoffrey Hinton 2016 : <a href="https://www.youtube.com/playlist?list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9" target="_blank" rel="noopener">YouTube</a></p>
</li>
</ol>
<h4 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h4><ol>
<li><p>Natural Language Processing with Deep Learning (Winter 2017) : <a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6" target="_blank" rel="noopener">YouTube</a></p>
</li>
<li><p><a href="https://github.com/yandexdataschool/nlp_course" target="_blank" rel="noopener">YSDA Natural Language Processing course</a></p>
</li>
</ol>
<hr>
<h3 id="BOOK"><a href="#BOOK" class="headerlink" title="BOOK"></a>BOOK</h3><ol>
<li>《机器学习》，周志华</li>
<li>《统计学习方法》，李航</li>
<li><a href="http://www.huaxiaozhuan.com/" target="_blank" rel="noopener">AI 算法工程师手册</a></li>
<li>Deep Learning : <a href="https://github.com/janishar/mit-deep-learning-book-pdf/blob/master/complete-book-bookmarked-pdf/deeplearningbook.pdf" target="_blank" rel="noopener">EN</a> , <a href="https://exacity.github.io/deeplearningbook-chinese/" target="_blank" rel="noopener">CN</a></li>
<li><a href="https://www.tinymind.cn/navigations/71?redirect=http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf" target="_blank" rel="noopener">Understanding Machine Learning From Theory to Algorithms</a></li>
<li><a href="http://www.mlyearning.org/" target="_blank" rel="noopener">Machine Learning Yearning</a></li>
<li><a href="https://www.intechopen.com/books/machine_learning" target="_blank" rel="noopener">Machine Learning</a></li>
<li>Neural Networks and Deep Learning : <a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="noopener">EN</a> , <a href="https://tigerneil.gitbooks.io/neural-networks-and-deep-learning-zh/content/" target="_blank" rel="noopener">CN</a></li>
</ol>
<hr>
<h3 id="SITE"><a href="#SITE" class="headerlink" title="SITE"></a>SITE</h3><ol>
<li><a href="https://www.tinymind.cn/" target="_blank" rel="noopener">https://www.tinymind.cn/</a></li>
<li><a href="https://morvanzhou.github.io/" target="_blank" rel="noopener">https://morvanzhou.github.io/(莫烦)</a></li>
<li><a href="https://course.fast.ai/" target="_blank" rel="noopener">https://course.fast.ai/</a></li>
</ol>
<h3 id="BLOG"><a href="#BLOG" class="headerlink" title="BLOG"></a>BLOG</h3><hr>
<h4 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h4><ol>
<li><a href="medium.com/@ageitgey">机器学习就是这么好玩！</a></li>
</ol>
<ul>
<li>机器学习速成课程（Berkeley的ML) : <a href="https://ml.berkeley.edu/blog/2016/11/06/tutorial-1/" target="_blank" rel="noopener">Part I</a> , <a href="https://ml.berkeley.edu/blog/2016/12/24/tutorial-2/" target="_blank" rel="noopener">Part II</a> , <a href="https://ml.berkeley.edu/blog/2017/02/04/tutorial-3/" target="_blank" rel="noopener">Part III</a></li>
</ul>
<ul>
<li><p><a href="https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer" target="_blank" rel="noopener">机器学习入门与应用：实例图解</a></p>
</li>
<li><p><a href="https://monkeylearn.com/blog/a-gentle-guide-to-machine-learning/" target="_blank" rel="noopener">机器学习的简易指南</a></p>
</li>
<li><p><a href="https://blogs.sas.com/content/subconsciousmusings/2017/04/12/machine-learning-algorithm-use/" target="_blank" rel="noopener">如何选择机器学习算法？(sas.com)</a></p>
</li>
</ul>
<ol>
<li>Activation and Loss Functions : 激活函数与损失函数</li>
</ol>
<ul>
<li><p><a href="http://neuralnetworksanddeeplearning.com/chap1.html#sigmoid_neurons" target="_blank" rel="noopener">sigmoid 神经元(neuralnetworksanddeeplearning.com)</a></p>
</li>
<li><p><a href="https://www.quora.com/What-is-the-role-of-the-activation-function-in-a-neural-network" target="_blank" rel="noopener">激活函数在神经网络中有什么作用？(quora.com)</a></p>
</li>
<li><p><a href="https://stats.stackexchange.com/questions/115258/comprehensive-list-of-activation-functions-in-neural-networks-with-pros-cons" target="_blank" rel="noopener">神经网络的激活函数大全及其优劣 (stats.stackexchange.com)</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://medium.com/towards-data-science/activation-functions-and-its-types-which-is-better-a9a5310cc8f" target="_blank" rel="noopener">激活函数及其分类比较(medium.com)</a></p>
</li>
<li><p><a href="http://www.exegetic.biz/blog/2015/12/making-sense-logarithmic-loss/" target="_blank" rel="noopener">理解对数损失 (exegetic.biz)</a></p>
</li>
<li><p><a href="http://cs231n.github.io/neural-networks-2/#losses" target="_blank" rel="noopener">损失函数(Stanford CS231n)</a></p>
</li>
<li><p><a href="http://rishy.github.io/ml/2015/07/28/l1-vs-l2-loss/" target="_blank" rel="noopener">损失函数L1 与L2 比较(rishy.github.io)</a></p>
</li>
<li><p><a href="http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-entropy_cost_function" target="_blank" rel="noopener">交叉熵损失函数(neuralnetworksanddeeplearning.com)</a></p>
</li>
</ul>
<ol>
<li>偏差（Bias）</li>
</ol>
<ul>
<li><p><a href="https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks/2499936#249993" target="_blank" rel="noopener">神经网络中的偏差的作用(stackoverflow.com)</a></p>
</li>
<li><p><a href="http://makeyourownneuralnetwork.blogspot.com/2016/06/bias-nodes-in-neural-networks.html" target="_blank" rel="noopener">神经网络中的偏差节点(makeyourownneuralnetwork.blogspot.com)</a></p>
</li>
<li><p><a href="https://www.quora.com/What-is-bias-in-artificial-neural-network" target="_blank" rel="noopener">什么是人工神经网络中的偏差 (quora.com)</a></p>
</li>
</ul>
<ol>
<li>感知器（Perceptron）</li>
</ol>
<ul>
<li><p><a href="http://neuralnetworksanddeeplearning.com/chap1.html#perceptrons" target="_blank" rel="noopener">感知器模型(neuralnetworksanddeeplearning.com)</a></p>
</li>
<li><p><a href="http://natureofcode.com/book/chapter-10-neural-networks/#chapter10_figure3" target="_blank" rel="noopener">感知器(natureofcode.com)</a></p>
</li>
<li><p><a href="http://computing.dcu.ie/~humphrys/Notes/Neural/single.neural.html" target="_blank" rel="noopener">一层的神经网络（感知器模型）(dcu.ie)</a></p>
</li>
<li><p><a href="https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks" target="_blank" rel="noopener">从感知器模型到深度网络(toptal.com)</a></p>
</li>
</ul>
<ol>
<li>回归算法</li>
</ol>
<ul>
<li><p><a href="http://people.duke.edu/~rnau/regintro.htm" target="_blank" rel="noopener">线性回归分析简介(duke.edu)</a></p>
</li>
<li><p><a href="http://ufldl.stanford.edu/tutorial/supervised/LinearRegression/" target="_blank" rel="noopener">线性回归 (ufldl.stanford.edu)</a></p>
</li>
<li><p><a href="http://ml-cheatsheet.readthedocs.io/en/latest/linear_regression.html" target="_blank" rel="noopener">线性回归 (readthedocs.io)</a></p>
</li>
<li><p><a href="http://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html" target="_blank" rel="noopener">逻辑斯特回归 (readthedocs.io)</a></p>
</li>
<li><p><a href="http://machinelearningmastery.com/simple-linear-regression-tutorial-for-machine-learning/" target="_blank" rel="noopener">机器学习之简单线性回归教程(machinelearningmastery.com)</a></p>
</li>
<li><p><a href="http://machinelearningmastery.com/logistic-regression-tutorial-for-machine-learning/" target="_blank" rel="noopener">机器学习之逻辑斯特回归教程(machinelearningmastery.com)</a></p>
</li>
<li><p><a href="http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/" target="_blank" rel="noopener">softmax 回归(ufldl.stanford.edu)</a></p>
</li>
</ul>
<ol>
<li>梯度下降</li>
</ol>
<ul>
<li><p><a href="neuralnetworksanddeeplearning.com">基于梯度下降的学习</a></p>
</li>
<li><p><a href="http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent" target="_blank" rel="noopener">http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent</a></p>
</li>
<li><p><a href="http://iamtrask.github.io/2015/07/27/python-network-part2/" target="_blank" rel="noopener">梯度下降(iamtrask.github.io)</a></p>
</li>
<li><p><a href="http://www.kdnuggets.com/2017/04/simple-understand-gradient-descent-algorithm.html" target="_blank" rel="noopener">如何理解梯度下降算法？(kdnuggets.com)</a></p>
</li>
<li><p><a href="http://sebastianruder.com/optimizing-gradient-descent/" target="_blank" rel="noopener">梯度下降优化算法概览(sebastianruder.com)</a></p>
</li>
<li><p><a href="http://cs231n.github.io/optimization-1/" target="_blank" rel="noopener">优化算法：随机梯度下降算法 (Stanford CS231n)</a></p>
</li>
</ul>
<ol>
<li>生成学习</li>
</ol>
<ul>
<li><p><a href="http://cs229.stanford.edu/notes/cs229-notes2.pdf" target="_blank" rel="noopener">生成学习算法 (Stanford CS229)</a></p>
<ul>
<li><a href="https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/" target="_blank" rel="noopener">贝叶斯分类算法之实例解析(monkeylearn.com)</a></li>
</ul>
</li>
</ul>
<ol>
<li>支持向量机</li>
</ol>
<ul>
<li><p><a href="https://monkeylearn.com/blog/introduction-to-support-vector-machines-svm/" target="_blank" rel="noopener">支持向量机（SVM）入门(monkeylearn.com)</a></p>
</li>
<li><p><a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener">支持向量机(Stanford CS229)</a></p>
</li>
<li><p><a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="noopener">线性分类：支持向量机，Softmax (Stanford 231n)</a></p>
</li>
</ul>
<ol>
<li>后向传播算法（Backpropagation）</li>
</ol>
<ul>
<li><p><a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b" target="_blank" rel="noopener">后向传播算法必知(medium.com/@karpathy)</a></p>
</li>
<li><p><a href="https://github.com/rasbt/python-machine-learning-book/blob/master/faq/visual-backpropagation.md" target="_blank" rel="noopener">来，给我图解一下神经网络后向传播算法？(github.com/rasbt)</a></p>
</li>
<li><p><a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank" rel="noopener">后向传播算法是如何运行的？(neuralnetworksanddeeplearning.com)</a></p>
</li>
<li><p><a href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/" target="_blank" rel="noopener">沿时后向传播算法与梯度消失(wildml.com)</a></p>
</li>
<li><p><a href="http://machinelearningmastery.com/gentle-introduction-backpropagation-time/" target="_blank" rel="noopener">简易入门沿时后向传播算法(machinelearningmastery.com)</a></p>
</li>
<li><p><a href="http://cs231n.github.io/optimization-2/" target="_blank" rel="noopener">奔跑吧，后向传播算法！(Stanford CS231n)</a></p>
</li>
</ul>
<ol>
<li>深度学习</li>
</ol>
<ul>
<li><p><a href="http://nikhilbuduma.com/2014/12/29/deep-learning-in-a-nutshell/" target="_blank" rel="noopener">果壳里的深度学习(nikhilbuduma.com)</a></p>
</li>
<li><p><a href="http://ai.stanford.edu/~quocle/tutorial1.pdf" target="_blank" rel="noopener">深度学习教程 (Quoc V. Le)</a></p>
</li>
<li><p><a href="http://machinelearningmastery.com/what-is-deep-learning/" target="_blank" rel="noopener">深度学习，什么鬼？(machinelearningmastery.com)</a></p>
</li>
<li><p><a href="https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/" target="_blank" rel="noopener">什么是人工智能，机器学习，深度学习之间的区别？ (nvidia.com)</a></p>
</li>
</ul>
<ol>
<li>优化算法与降维算法</li>
</ol>
<ul>
<li><p><a href="https://www.knime.org/blog/seven-techniques-for-data-dimensionality-reduction" target="_blank" rel="noopener">数据降维的七招炼金术(knime.org)</a></p>
</li>
<li><p><a href="http://cs229.stanford.edu/notes/cs229-notes10.pdf" target="_blank" rel="noopener">主成分分析(Stanford CS229)</a></p>
</li>
<li><p><a href="http://videolectures.net/site/normal_dl/tag=741100/nips2012_hinton_networks_01.pdf" target="_blank" rel="noopener">Dropout: 改进神经网络的一个简单方法(Hinton @ NIPS 2012)</a></p>
</li>
<li><p><a href="http://rishy.github.io/ml/2017/01/05/how-to-train-your-dnn/" target="_blank" rel="noopener">如何溜你们家的深度神经网络？(rishy.github.io)</a></p>
</li>
</ul>
<ol>
<li>长短期记忆(LSTM) </li>
</ol>
<ul>
<li><p><a href="http://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/" target="_blank" rel="noopener">老司机带你简易入门长短期神经网络(machinelearningmastery.com)</a></p>
</li>
<li><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">理解LSTM网络(colah.github.io)</a></p>
</li>
<li><p><a href="http://blog.echen.me/2017/05/30/exploring-lstms/" target="_blank" rel="noopener">漫谈LSTM模型(echen.me)</a></p>
</li>
<li><p><a href="http://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/" target="_blank" rel="noopener">小学生看完这教程都可以用Python实现一个LSTM-RNN (iamtrask.github.io)</a></p>
</li>
</ul>
<ol>
<li>卷积神经网络（CNNs）</li>
</ol>
<ul>
<li><p><a href="http://neuralnetworksanddeeplearning.com/chap6.html#introducing_convolutional_networks" target="_blank" rel="noopener">卷积网络入门(neuralnetworksanddeeplearning.com)</a></p>
</li>
<li><p><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721" target="_blank" rel="noopener">深度学习与卷积神经网络模型(medium.com/@ageitgey)</a></p>
</li>
<li><p><a href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/" target="_blank" rel="noopener">拆解卷积网络模型(colah.github.io)</a></p>
</li>
<li><p><a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/" target="_blank" rel="noopener">理解卷积网络(colah.github.io)</a></p>
</li>
</ul>
<ol>
<li>递归神经网络(RNNs)</li>
</ol>
<ul>
<li><p><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="noopener">递归神经网络教程 (wildml.com)</a></p>
</li>
<li><p><a href="http://distill.pub/2016/augmented-rnns/" target="_blank" rel="noopener">注意力模型与增强型递归神经网络(distill.pub)</a></p>
</li>
<li><p><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">这么不科学的递归神经网络模型(karpathy.github.io)</a></p>
</li>
<li><p><a href="http://nikhilbuduma.com/2015/01/11/a-deep-dive-into-recurrent-neural-networks/" target="_blank" rel="noopener">深入递归神经网络模型(nikhilbuduma.com)</a></p>
</li>
</ul>
<ol>
<li>强化学习</li>
</ol>
<ul>
<li><p><a href="https://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/" target="_blank" rel="noopener">给小白看的强化学习及其实现指南 (analyticsvidhya.com)</a></p>
</li>
<li><p><a href="https://web.mst.edu/~gosavia/tutorial.pdf" target="_blank" rel="noopener">强化学习教程(mst.edu)</a></p>
</li>
<li><p><a href="http://www.wildml.com/2016/10/learning-reinforcement-learning/" target="_blank" rel="noopener">强化学习，你学了么？(wildml.com)</a></p>
</li>
<li><p><a href="http://karpathy.github.io/2016/05/31/rl/" target="_blank" rel="noopener">深度强化学习：开挂玩Pong (karpathy.github.io)</a></p>
</li>
</ul>
<ol>
<li>对抗式生成网络模型(GANs)</li>
</ol>
<ul>
<li><p><a href="https://blogs.nvidia.com/blog/2017/05/17/generative-adversarial-network/" target="_blank" rel="noopener">什么是对抗式生成网络模型？(nvidia.com)</a></p>
</li>
<li><p><a href="https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7" target="_blank" rel="noopener">用对抗式生成网络创造8个像素的艺术(medium.com/@ageitgey)</a></p>
</li>
<li><p><a href="http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/" target="_blank" rel="noopener">对抗式生成网络入门（TensorFlow）(aylien.com)</a></p>
</li>
<li><p><a href="https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners" target="_blank" rel="noopener">《对抗式生成网络》（小学一年级~上册）(oreilly.com)</a></p>
</li>
</ul>
<ol>
<li>多任务学习</li>
</ol>
<ul>
<li><a href="http://sebastianruder.com/multi-task/index.html" target="_blank" rel="noopener">深度神经网络中的多任务学习概述(sebastianruder.com)</a></li>
</ul>
<h4 id="NLP-1"><a href="#NLP-1" class="headerlink" title="NLP"></a>NLP</h4><ol>
<li>NLP</li>
</ol>
<ul>
<li><p><a href="http://u.cs.biu.ac.il/~yogo/nnlp.pdf" target="_blank" rel="noopener">《基于神经网络模型的自然语言处理》（小学一年级~上册）(Yoav Goldberg)</a></p>
</li>
<li><p><a href="https://monkeylearn.com/blog/the-definitive-guide-to-natural-language-processing/" target="_blank" rel="noopener">自然语言处理权威指南(monkeylearn.com)</a></p>
</li>
<li><p><a href="https://blog.algorithmia.com/introduction-natural-language-processing-nlp/" target="_blank" rel="noopener">自然语言处理入门(algorithmia.com)</a></p>
</li>
<li><p><a href="http://www.vikparuchuri.com/blog/natural-language-processing-tutorial/" target="_blank" rel="noopener">自然语言处理教程 (vikparuchuri.com)</a></p>
</li>
<li><p>[初高中生课程：自然语言处理 (arxiv.org)]<br>(<a href="https://arxiv.org/pdf/1103.0398.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1103.0398.pdf</a>)</p>
</li>
</ul>
<ol>
<li>深度学习和 NLP</li>
</ol>
<ul>
<li><p><a href="https://arxiv.org/pdf/1703.03091.pdf" target="_blank" rel="noopener">基于深度学习的NLP应用(arxiv.org)</a></p>
</li>
<li><p><a href="https://nlp.stanford.edu/courses/NAACL2013/NAACL2013-Socher-Manning-DeepLearning.pdf" target="_blank" rel="noopener">基于深度学习的NLP(Richard Socher)</a></p>
</li>
<li><p><a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/" target="_blank" rel="noopener">理解卷积神经网络在NLP中的应用(wildml.com)</a></p>
</li>
<li><p><a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/" target="_blank" rel="noopener">深度学习，NLP，表示学习(colah.github.io)</a></p>
</li>
<li><p><a href="https://explosion.ai/blog/deep-learning-formula-nlp" target="_blank" rel="noopener">嵌入表示，编码，注意力，预测 : 新一代深度学习因NLP的精妙而存在(explosion.ai)</a></p>
</li>
<li><p><a href="https://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/" target="_blank" rel="noopener">理解基于神经网络的自然语言处理(Torch实现) (nvidia.com)</a></p>
</li>
<li><p><a href="http://pytorch.org/tutorials/beginner/deep_learning_nlp_tutorial.html" target="_blank" rel="noopener">深度学习在NLP中的应用(Pytorch实现) (pytorich.org)</a></p>
</li>
</ul>
<ol>
<li><p>词向量（Word Vectors）</p>
<ul>
<li><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial" target="_blank" rel="noopener">词袋法遇到感知器装袋法(kaggle.com)</a></li>
</ul>
</li>
</ol>
<ul>
<li><p>学习单词嵌入表示法(sebastianruder.com) : <a href="http://sebastianruder.com/word-embeddings-1/index.html" target="_blank" rel="noopener">Part I</a> , <a href="http://sebastianruder.com/word-embeddings-softmax/index.html" target="_blank" rel="noopener">Part II</a> , <a href="http://sebastianruder.com/secret-word2vec/index.html" target="_blank" rel="noopener">Part III</a></p>
</li>
<li><p><a href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/" target="_blank" rel="noopener">单词嵌入表示的神奇力量(acolyer.org)</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/1411.2738.pdf" target="_blank" rel="noopener">解释word2vec 的参数学习(arxiv.org)</a></p>
</li>
<li><p><a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/" target="_blank" rel="noopener">word2vec教程 skip-gram 模型，负采样(mccormickml.com)</a></p>
</li>
</ul>
<ol>
<li><p>Encoder-Decoder</p>
<ul>
<li><a href="http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/" target="_blank" rel="noopener">注意力机制与记忆机制在深度学习与NLP中的应用(wildml.com)</a></li>
</ul>
</li>
</ol>
<ul>
<li><p><a href="https://www.tensorflow.org/tutorials/seq2seq" target="_blank" rel="noopener">序列到序列模型(tensorflow.org)</a></p>
</li>
<li><p><a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" target="_blank" rel="noopener">利用神经网络学习序列到序列模型(NIPS 2014)</a></p>
</li>
<li><p><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa" target="_blank" rel="noopener">基于深度学习和魔法序列的语言翻译(medium.com/@ageitgey)</a></p>
</li>
<li><p><a href="http://machinelearningmastery.com/how-to-use-an-encoder-decoder-lstm-to-echo-sequences-of-random-integers/" target="_blank" rel="noopener">如何使用编码-解码LSTM输出随机整数对应的序列(machinelearningmastery.com)</a></p>
</li>
<li><p><a href="https://google.github.io/seq2seq/" target="_blank" rel="noopener">tf-seq2seq (google.github.io)</a></p>
</li>
</ul>
<h4 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h4><ol>
<li>Python</li>
</ol>
<p>使用Python精通机器学习的七步法(kdnuggets.com)</p>
<p><a href="http://www.kdnuggets.com/2015/11/seven-steps-machine-learning-python.html" target="_blank" rel="noopener">http://www.kdnuggets.com/2015/11/seven-steps-machine-learning-python.html</a></p>
<p>机器学习的一个简例(nbviewer.jupyter.org)</p>
<p><a href="http://nbviewer.jupyter.org/github/rhiever/Data-Analysis-and-Machine-Learning-Projects/blob/master/example-data-science-notebook/Example" target="_blank" rel="noopener">http://nbviewer.jupyter.org/github/rhiever/Data-Analysis-and-Machine-Learning-Projects/blob/master/example-data-science-notebook/Example</a> Machine Learning Notebook.ipynb</p>
<ol>
<li>实例</li>
</ol>
<p>小白如何用python实现感知器算法(machinelearningmastery.com)</p>
<p><a href="http://machinelearningmastery.com/implement-perceptron-algorithm-scratch-python/" target="_blank" rel="noopener">http://machinelearningmastery.com/implement-perceptron-algorithm-scratch-python/</a></p>
<p>小学生用python实现一个神经网络(wildml.com)</p>
<p><a href="http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/" target="_blank" rel="noopener">http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/</a></p>
<p>只用11行python代码实现一个神经网络算法(iamtrask.github.io)</p>
<p><a href="http://iamtrask.github.io/2015/07/12/basic-python-network/" target="_blank" rel="noopener">http://iamtrask.github.io/2015/07/12/basic-python-network/</a></p>
<p>自己动手用ptython实现最近邻算法(kdnuggets.com)</p>
<p><a href="http://www.kdnuggets.com/2016/01/implementing-your-own-knn-using-python.html" target="_blank" rel="noopener">http://www.kdnuggets.com/2016/01/implementing-your-own-knn-using-python.html</a></p>
<p>python实现长短期记忆网络的记忆机制(machinelearningmastery.com)</p>
<p><a href="http://machinelearningmastery.com/memory-in-a-long-short-term-memory-network/" target="_blank" rel="noopener">http://machinelearningmastery.com/memory-in-a-long-short-term-memory-network/</a></p>
<p>如何用长短期记忆递归神经网络输出随机整数(machinelearningmastery.com)</p>
<p><a href="http://machinelearningmastery.com/learn-echo-random-integers-long-short-term-memory-recurrent-neural-networks/" target="_blank" rel="noopener">http://machinelearningmastery.com/learn-echo-random-integers-long-short-term-memory-recurrent-neural-networks/</a></p>
<p>如何用seq2seq递归神经网络学习加法运算(machinelearningmastery.com)</p>
<p><a href="http://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neural-networks/" target="_blank" rel="noopener">http://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neural-networks/</a></p>
<ol>
<li>Scipy 和 numpy</li>
</ol>
<p>Scipy课程笔记(scipy-lectures.org)</p>
<p><a href="http://www.scipy-lectures.org/" target="_blank" rel="noopener">http://www.scipy-lectures.org/</a></p>
<p>Python Numpy 教程(Stanford CS231n)</p>
<p><a href="http://cs231n.github.io/python-numpy-tutorial/" target="_blank" rel="noopener">http://cs231n.github.io/python-numpy-tutorial/</a></p>
<p>Numpy 与 Scipy 入门(UCSB CHE210D)</p>
<p><a href="https://engineering.ucsb.edu/~shell/che210d/numpy.pdf" target="_blank" rel="noopener">https://engineering.ucsb.edu/~shell/che210d/numpy.pdf</a></p>
<p>给科学家看的Python微课程(nbviewer.jupyter.org)</p>
<p><a href="http://nbviewer.jupyter.org/gist/rpmuller/5920182#ii.-numpy-and-scipy" target="_blank" rel="noopener">http://nbviewer.jupyter.org/gist/rpmuller/5920182#ii.-numpy-and-scipy</a></p>
<ol>
<li>scikit-learn</li>
</ol>
<p>PyCon会议上的Scik-learn 教程(nbviewer.jupyter.org)</p>
<p><a href="http://nbviewer.jupyter.org/github/jakevdp/sklearn_pycon2015/blob/master/notebooks/Index.ipynb" target="_blank" rel="noopener">http://nbviewer.jupyter.org/github/jakevdp/sklearn_pycon2015/blob/master/notebooks/Index.ipynb</a></p>
<p>Scikit-learn 中的分类算法(github.com/mmmayo13)</p>
<p><a href="https://github.com/mmmayo13/scikit-learn-classifiers/blob/master/sklearn-classifiers-tutorial.ipynb" target="_blank" rel="noopener">https://github.com/mmmayo13/scikit-learn-classifiers/blob/master/sklearn-classifiers-tutorial.ipynb</a></p>
<p>Scikit-learn教程(scikit-learn.org)</p>
<p><a href="http://scikit-learn.org/stable/tutorial/index.html" target="_blank" rel="noopener">http://scikit-learn.org/stable/tutorial/index.html</a></p>
<p>简明版Scikit-learn教程(github.com/mmmayo13)</p>
<p><a href="https://github.com/mmmayo13/scikit-learn-beginners-tutorials" target="_blank" rel="noopener">https://github.com/mmmayo13/scikit-learn-beginners-tutorials</a></p>
<ol>
<li>Tensorflow</li>
</ol>
<p>Tensorflow教程(tensorflow.org)</p>
<p><a href="https://www.tensorflow.org/tutorials/" target="_blank" rel="noopener">https://www.tensorflow.org/tutorials/</a></p>
<p>Tensorflow入门—CPU vs GPU</p>
<p> (medium.com/@erikhallstrm)</p>
<p><a href="https://medium.com/@erikhallstrm/hello-world-tensorflow-649b15aed18c" target="_blank" rel="noopener">https://medium.com/@erikhallstrm/hello-world-tensorflow-649b15aed18c</a></p>
<p>Tensorflow入门(metaflow.fr)</p>
<p><a href="https://blog.metaflow.fr/tensorflow-a-primer-4b3fa0978be3" target="_blank" rel="noopener">https://blog.metaflow.fr/tensorflow-a-primer-4b3fa0978be3</a></p>
<p>Tensorflow实现RNNs (wildml.com)</p>
<p><a href="http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/" target="_blank" rel="noopener">http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/</a></p>
<p>Tensorflow实现文本分类CNN模型(wildml.com)</p>
<p><a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/" target="_blank" rel="noopener">http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/</a></p>
<p>如何用Tensorflow做文本摘要(surmenok.com)</p>
<p><a href="http://pavel.surmenok.com/2016/10/15/how-to-run-text-summarization-with-tensorflow/" target="_blank" rel="noopener">http://pavel.surmenok.com/2016/10/15/how-to-run-text-summarization-with-tensorflow/</a></p>
<ol>
<li>PyTorch</li>
</ol>
<p>Pytorch教程(pytorch.org)</p>
<p><a href="http://pytorch.org/tutorials/" target="_blank" rel="noopener">http://pytorch.org/tutorials/</a></p>
<p>Pytorch快手入门 (gaurav.im)</p>
<p><a href="http://blog.gaurav.im/2017/04/24/a-gentle-intro-to-pytorch/" target="_blank" rel="noopener">http://blog.gaurav.im/2017/04/24/a-gentle-intro-to-pytorch/</a></p>
<p>利用Pytorch深度学习教程(iamtrask.github.io)</p>
<p><a href="https://iamtrask.github.io/2017/01/15/pytorch-tutorial/" target="_blank" rel="noopener">https://iamtrask.github.io/2017/01/15/pytorch-tutorial/</a></p>
<p>Pytorch实战(github.com/jcjohnson)</p>
<p><a href="https://github.com/jcjohnson/pytorch-examples" target="_blank" rel="noopener">https://github.com/jcjohnson/pytorch-examples</a></p>
<p>PyTorch 教程(github.com/MorvanZhou)</p>
<p><a href="https://github.com/MorvanZhou/PyTorch-Tutorial" target="_blank" rel="noopener">https://github.com/MorvanZhou/PyTorch-Tutorial</a></p>
<p>深度学习研究人员看的PyTorch教程(github.com/yunjey)</p>
<p><a href="https://github.com/yunjey/pytorch-tutorial" target="_blank" rel="noopener">https://github.com/yunjey/pytorch-tutorial</a></p>
<h3 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h3><ol>
<li>机器学习中的数学 (ucsc.edu)</li>
</ol>
<p><a href="https://people.ucsc.edu/~praman1/static/pub/math-for-ml.pdf" target="_blank" rel="noopener">https://people.ucsc.edu/~praman1/static/pub/math-for-ml.pdf</a></p>
<p>机器学习数学基础(UMIACS CMSC422)</p>
<p><a href="http://www.umiacs.umd.edu/~hal/courses/2013S_ML/math4ml.pdf" target="_blank" rel="noopener">http://www.umiacs.umd.edu/~hal/courses/2013S_ML/math4ml.pdf</a></p>
<ol>
<li>线性代数</li>
</ol>
<p>线性代数简明指南(betterexplained.com)</p>
<p><a href="https://betterexplained.com/articles/linear-algebra-guide/" target="_blank" rel="noopener">https://betterexplained.com/articles/linear-algebra-guide/</a></p>
<p>码农眼中矩阵乘法 (betterexplained.com)</p>
<p><a href="https://betterexplained.com/articles/matrix-multiplication/" target="_blank" rel="noopener">https://betterexplained.com/articles/matrix-multiplication/</a></p>
<p>理解叉乘运算(betterexplained.com)</p>
<p><a href="https://betterexplained.com/articles/cross-product/" target="_blank" rel="noopener">https://betterexplained.com/articles/cross-product/</a></p>
<p>理解点乘运算(betterexplained.com)</p>
<p><a href="https://betterexplained.com/articles/vector-calculus-understanding-the-dot-product/" target="_blank" rel="noopener">https://betterexplained.com/articles/vector-calculus-understanding-the-dot-product/</a></p>
<p>机器学习中的线性代数(U. of Buffalo CSE574)</p>
<p><a href="http://www.cedar.buffalo.edu/~srihari/CSE574/Chap1/LinearAlgebra.pdf" target="_blank" rel="noopener">http://www.cedar.buffalo.edu/~srihari/CSE574/Chap1/LinearAlgebra.pdf</a></p>
<p>深度学习的线代小抄(medium.com)</p>
<p><a href="https://medium.com/towards-data-science/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c" target="_blank" rel="noopener">https://medium.com/towards-data-science/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c</a></p>
<p>复习线性代数与课后阅读材料(Stanford CS229)</p>
<p><a href="http://cs229.stanford.edu/section/cs229-linalg.pdf" target="_blank" rel="noopener">http://cs229.stanford.edu/section/cs229-linalg.pdf</a></p>
<ol>
<li>概率论</li>
</ol>
<p>贝叶斯理论 (betterexplained.com)</p>
<p><a href="https://betterexplained.com/articles/understanding-bayes-theorem-with-ratios/" target="_blank" rel="noopener">https://betterexplained.com/articles/understanding-bayes-theorem-with-ratios/</a></p>
<p>理解贝叶斯概率理论(Stanford CS229)</p>
<p><a href="http://cs229.stanford.edu/section/cs229-prob.pdf" target="_blank" rel="noopener">http://cs229.stanford.edu/section/cs229-prob.pdf</a></p>
<p>复习机器学习中的概率论(Stanford CS229)</p>
<p><a href="https://see.stanford.edu/materials/aimlcs229/cs229-prob.pdf" target="_blank" rel="noopener">https://see.stanford.edu/materials/aimlcs229/cs229-prob.pdf</a></p>
<p>概率论(U. of Buffalo CSE574)</p>
<p><a href="http://www.cedar.buffalo.edu/~srihari/CSE574/Chap1/Probability-Theory.pdf" target="_blank" rel="noopener">http://www.cedar.buffalo.edu/~srihari/CSE574/Chap1/Probability-Theory.pdf</a></p>
<p>机器学习中的概率论(U. of Toronto CSC411)</p>
<p><a href="http://www.cs.toronto.edu/~urtasun/courses/CSC411_Fall16/tutorial1.pdf" target="_blank" rel="noopener">http://www.cs.toronto.edu/~urtasun/courses/CSC411_Fall16/tutorial1.pdf</a></p>
<ol>
<li>计算方法（Calculus）</li>
</ol>
<p>如何理解导数：求导法则，指数和算法(betterexplained.com)</p>
<p><a href="https://betterexplained.com/articles/how-to-understand-derivatives-the-quotient-rule-exponents-and-logarithms/" target="_blank" rel="noopener">https://betterexplained.com/articles/how-to-understand-derivatives-the-quotient-rule-exponents-and-logarithms/</a></p>
<p>如何理解导数，乘法，幂指数，链式法(betterexplained.com)</p>
<p><a href="https://betterexplained.com/articles/derivatives-product-power-chain/" target="_blank" rel="noopener">https://betterexplained.com/articles/derivatives-product-power-chain/</a></p>
<p>向量计算，理解梯度(betterexplained.com)</p>
<p><a href="https://betterexplained.com/articles/vector-calculus-understanding-the-gradient/" target="_blank" rel="noopener">https://betterexplained.com/articles/vector-calculus-understanding-the-gradient/</a></p>
<p>微分计算(Stanford CS224n)</p>
<p><a href="http://web.stanford.edu/class/cs224n/lecture_notes/cs224n-2017-review-differential-calculus.pdf" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/lecture_notes/cs224n-2017-review-differential-calculus.pdf</a></p>
<p>计算方法概论(readthedocs.io)</p>
<p><a href="http://ml-cheatsheet.readthedocs.io/en/latest/calculus.html" target="_blank" rel="noopener">http://ml-cheatsheet.readthedocs.io/en/latest/calculus.html</a></p>
<hr>
<p>THE.</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">


    <div class="bdsharebuttonbox">
    <a href="#" class="bds_more" data-cmd="more">分享到：</a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间">QQ空间</a>
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博">新浪微博</a>
    <a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博">腾讯微博</a>
    <a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网">人人网</a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信">微信</a>
</div>
<script>
window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"share":{"bdSize":16}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>
<style>
    .bdshare_popup_box {
        border-radius: 4px;
        border: #e1e1e1 solid 1px;
    }
    .bdshare-button-style0-16 a,
    .bdshare-button-style0-16 .bds_more {
        padding-left: 20px;
        margin: 6px 10px 6px 0;
    }
    .bdshare_dialog_list a,
    .bdshare_popup_list a,
    .bdshare_popup_bottom a {
        font-family: 'Microsoft Yahei';
    }
    .bdshare_popup_top {
        display: none;
    }
    .bdshare_popup_bottom {
        height: auto;
        padding: 5px;
    }
</style>


</div>

            
    
        <a href="http://ai.wisim.me/1970/01/03/2018-11-21-course/#comments" class="article-comment-link">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/1970/01/04/1970-01-04_BaseConcept/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    基本概念
                
            </div>
        </a>
    
    
        <a href="/1970/01/02/1970-01-02_sklearn_tricks/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">sklearn 技巧</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div id="lv-container" data-id="city" data-uid=MTAyMC8zNDc5NS8xMTMzMg==></div>
</section>
    

</section>
            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2018 Wisimer<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        
    
    
    <!-- 来必力City版安装代码 -->
    <script type="text/javascript">
     (function(d, s) {
         var j, e = d.getElementsByTagName(s)[0];

         if (typeof LivereTower === 'function') { return; }

         j = d.createElement(s);
         j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
         j.async = true;

         e.parentNode.insertBefore(j, e);
     })(document, 'script');
    </script>
  <noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
  <!-- City版安装代码已完成 -->





    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>