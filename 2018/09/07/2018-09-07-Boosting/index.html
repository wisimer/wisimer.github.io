<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>AdaBoost 简介【译】 | XP</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="原文：AdaBoost 简介 目前的集成学习（Ensemble Learning）方法大致可分为两类：一是个体学习器之间存在强依赖关系、必须串行生成的序列化方法，代表算法是Boosting；二是个体学习器之间不存在强依赖关系，可同时生成的并行方法，代表算法是 Bagging 和 “随机森林（Random Forest）”。 首先要知道 AdaBoost(adaptive boosting) 算法是">
<meta name="keywords" content="Boosting,AdaBoost">
<meta property="og:type" content="article">
<meta property="og:title" content="AdaBoost 简介【译】">
<meta property="og:url" content="http://ai.wisim.me/2018/09/07/2018-09-07-Boosting/index.html">
<meta property="og:site_name" content="XP">
<meta property="og:description" content="原文：AdaBoost 简介 目前的集成学习（Ensemble Learning）方法大致可分为两类：一是个体学习器之间存在强依赖关系、必须串行生成的序列化方法，代表算法是Boosting；二是个体学习器之间不存在强依赖关系，可同时生成的并行方法，代表算法是 Bagging 和 “随机森林（Random Forest）”。 首先要知道 AdaBoost(adaptive boosting) 算法是">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://ai.wisim.me/src/imgs/1809/0907_boosting.png">
<meta property="og:image" content="http://ai.wisim.me/src/imgs/1809/0907_smatrix.png">
<meta property="og:updated_time" content="2018-09-10T13:21:18.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AdaBoost 简介【译】">
<meta name="twitter:description" content="原文：AdaBoost 简介 目前的集成学习（Ensemble Learning）方法大致可分为两类：一是个体学习器之间存在强依赖关系、必须串行生成的序列化方法，代表算法是Boosting；二是个体学习器之间不存在强依赖关系，可同时生成的并行方法，代表算法是 Bagging 和 “随机森林（Random Forest）”。 首先要知道 AdaBoost(adaptive boosting) 算法是">
<meta name="twitter:image" content="http://ai.wisim.me/src/imgs/1809/0907_boosting.png">
    

    
        <link rel="alternate" href="/" title="XP" type="application/atom+xml" />
    

    
        <link rel="icon" href="https://github.com/wisimer/wisimer.github.io/blob/master/css/images/logo.png?raw=true" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?c87f7ac22d7007b78c0d4fa544da6c44";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    


</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">XP</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">HOME</a>
                
                    <a class="main-nav-link" href="/archives">ARCHIVE</a>
                
                    <a class="main-nav-link" href="/categories">CATEGOTY</a>
                
                    <a class="main-nav-link" href="/about">ABOUT</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">HOME</a></td>
                
                    <td><a class="main-nav-link" href="/archives">ARCHIVE</a></td>
                
                    <td><a class="main-nav-link" href="/categories">CATEGOTY</a></td>
                
                    <td><a class="main-nav-link" href="/about">ABOUT</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            <section id="main"><article id="post-2018-09-07-Boosting" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            AdaBoost 简介【译】
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2018/09/07/2018-09-07-Boosting/">
            <time datetime="2018-09-06T16:00:00.000Z" itemprop="datePublished">2018-09-07</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/ML/">ML</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/AdaBoost/">AdaBoost</a>, <a class="tag-link" href="/tags/Boosting/">Boosting</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>原文：<a href="http://www.inf.fu-berlin.de/inst/ag-ki/adaboost4.pdf" target="_blank" rel="noopener">AdaBoost 简介</a></p>
<p>目前的<code>集成学习（Ensemble Learning）</code>方法大致可分为两类：一是个体学习器之间存在强依赖关系、必须串行生成的序列化方法，代表算法是Boosting；二是个体学习器之间不存在强依赖关系，可同时生成的并行方法，代表算法是 Bagging 和 “随机森林（Random Forest）”。</p>
<p>首先要知道 <code>AdaBoost(adaptive boosting) 算法</code>是<code>Boosting算法族</code>中的一员。Boosting算法可将弱学习器提升为强学习器。所谓的弱学习器就是泛化性能略高于随机猜测的学习器，而强学习器很显然就是指泛化能力较高的学习器了。Boosting算法原理图：</p>
<p><img src="/src/imgs/1809/0907_boosting.png" alt="Boosting"></p>
<p>AdaBoost算法中有一个很重要的环节。每一个训练样本都被赋予权值，并且随着训练过程样本权值不断更新。更新的原则是：误分类样本被赋予更高的权值，而正确分类样本的权值被相应降低。通过这种方式能够将重点放在不能正确分类的样本上，新选出来的分类器能够发挥原有分类器没有的作用，提高整体的分类效果。<br><a id="more"></a></p>
<h4 id="一、算法目标"><a href="#一、算法目标" class="headerlink" title="一、算法目标"></a>一、算法目标</h4><p>如果你正在处理一个二分类模式识别问题，并且现在提供了一系列分类器，你可以从中选择使用哪些分类器（我们这里称之为小能手）。现在你想从中选出最优的几个小能手参加“超级碗”比赛。因此，你要选出一个十一人梦之队。假设给定的数据 $x_i$ 和每个分类器（小能手） $k_j$ 可以发表一个观点 $k_j(x_i) \in{\{-1,1\}}$，并且根据这些观点最终得出的决定是 sign(C(x_i))，这个 <code>sign</code>函数是所有小能手提出的观点的带权之和：</p>
<script type="math/tex; mode=display">C(x_i)=a_1k_1(x_i)+a_2k_2(x_i)+...+a_11k_11(x_i)</script><p>这里的 $k_1,k_2,…,k_11$ 表示这十一个小能手代表的时哪一种分类器。然后前面的常数 $a_1,a_2,…,a_11$ 是我们给定的每个小能手的权重。此外，小能手 $K_j$ 只能回答 “yes(+1)” 或者 “no(-1)” 来对问题分类。这里的 <code>sign 函数</code>是一个非线性决策，它是由这一些列线性分类器组合而成。</p>
<h4 id="二、寻找合适的分类器"><a href="#二、寻找合适的分类器" class="headerlink" title="二、寻找合适的分类器"></a>二、寻找合适的分类器</h4><p>如果你也想参加我们这个分类器比赛，你要做的是：1）找到适合的队员，2）召集他们，3）根据他们的贡献给他们分配权重值。</p>
<p>寻找合适队员的工作是通过使用分类器训练数据集 N 中的一部分 T 来完成，N中得数据就是一个多维数据点 $x_i$。对于每一个 $x_i$ ，它们都有一个相对应的标签 $y_i = 1$ 或者 $y_i=-1$。如果分类器判断错误，我们就给这个分类器减去一个值 $e^{\beta}$，如果分类器判断正确，我们就给这个分类器减去一个值 $e^{-\beta}$，这样对所有的分类器进行测试和排序。这里的 $\beta &gt; 0$，所以会保证判断错误的惩罚值会比判断正确地要高。不过也许你会奇怪，为什么判断正确还要给一个惩罚值，但其实只要判断正确的惩罚值小于判断错误的惩罚值（$e^{-\beta}&lt;e^{\beta}$），那就是没有问题的。这类错误函数和常用的欧式距离不同，它是一种指数损失函数。AdaBoost就是使用的指数损失函数作为错误惩罚函数。</p>
<p>在测试这些分类器的时候，对于某一个分类器 L，我们构建一个矩阵 S，S 用1记录判断错误，用0记录判断正确。矩阵的列代表着每个数据点 $x_i$，列代表着第 j 个分类器：</p>
<p><img src="/src/imgs/1809/0907_smatrix.png" alt="分类器"></p>
<p>在上面这个例子里，我们可以看到第一个分类器对第1，2和N这三个点得判断正确，对第3个点的判断错误。其他的分类器对数据点的判断结果也显而易见。</p>
<p>AdaBoost算法的主要思想就是通过自动迭代挑选出分类器。每次迭代的当前相关性（或者叫重要性）决定了数据集中得元素的权重。一开始，所有元素都分配的时相同的权重（1或者1/N，保持权重之和为1）。随着挑选的过程，越难判别的元素就会让它们的权重越高。这个挑选的过程就是选出对这些难判别元素分类效果较好地分类器。如果每次挑选的分类器只适用于那些已经可以正确判断的元素，那这个挑选的过程就没有意义了。如果想两次都挑选一个分类器，那直接复制它的权重即可。最好的“队员”就是能为团队提供新视野的人。挑选的分类器一定要最佳互补。“并不是每个人都能做四分卫的”。</p>
<h4 id="三、征集分类器"><a href="#三、征集分类器" class="headerlink" title="三、征集分类器"></a>三、征集分类器</h4><p>每次迭代我们都要对所有分类器排序，然后选出最佳分类器。假设在第 m 次迭代时，我们已经筛选出了 m-1 个分类器，现在要选择下一个了。当前筛选出的 m-1 个分类器的线性组合如下：</p>
<script type="math/tex; mode=display">C_{m-1}(x_i)=a_1k_1(x_i)+a_2k2_(x_i)+...+a_{m-1}k_{m-1}(x_i) \tag{3.1}</script><p>所以扩展到第 m 个分类器时，线性组合表示为：</p>
<script type="math/tex; mode=display">C_m(x_i)=C_{m-1}(x_i)+a_mk_m(x_i) \tag{3.2}</script><p>在第一次迭代的时候 m=1,C_{m-1} 是 0 。我们为第 m 个线性组合定义了总的代价或者总的错误作为指数损失为：</p>
<script type="math/tex; mode=display">E=\sum_{i=1}^m e^{-y_i(C_{(m-1)}(x_i)+a_mk_m(x_i))} \tag{3.3}</script><p>这里的 $a_m$ 和 $k_m$ 要通过优化方式得到。既然我们目标是要得到 $k_m$，这里重写一下上面的公式3.3：</p>
<script type="math/tex; mode=display">E=\sum_{i=1}^mw_i^{(m)}e^{-y_ia_mk_m(x_i)},w_i^{(m)}=e^{-y_iC_{(m-1)(x_i)}} \tag{3.4}</script><p>注意这里的上标 m 不是幂，而是第 m 个；下标 m-1 也是代表第 m-1 个。i=1,….,N。</p>
<p>在第一次迭代中， $w_i^{(1)}=1,i=1,…,N$。而后面的迭代中，向量 $w^{(m)}$ 代表着<code>第 m 次迭代分配给数据点的权重</code>。我们可以把上面的公式3.4拆分成两个和：</p>
<script type="math/tex; mode=display">E=\sum_{y_i=k_m(x_i)}w_i^{(m)}e^{-a_m}+\sum_{y_i\neq k_m(x_i)}w_i^{(m)}e^{a_m} \tag{3.5}</script><p>公式3.5很重要，它表示总的代价就是判断正确的代价之和加上判断错误的代价之和（之前已经说过判断对错都要给一个代价）。把第一个代价和（判断正确代价和）表示为 $W_ce^{-a_m}$ ，然后第二个代价和（判断错误代价和）表示为 $W_ee^{a_m}$，所以公式3.5就可以表示为如下：</p>
<script type="math/tex; mode=display">E=W_ce^{-a_m}+W_ee^{a_m} \tag{3.6}</script><p>由于分类器 $k_m$ 的选择和 $a_m(a_m&gt;0)$ 的具体值没有关系，所以对于一个固定的 $a_m$ 值来说，最小化代价函数 E 就等价于最小化 $e^{a_m}E$，同时因为公式3.6左右两边同时乘以 $e^{a_m}$ 得。</p>
<script type="math/tex; mode=display">e^{a_m}E=W_c+W_ee^{2a_m} \tag{3.7}</script><p>又因为 $e^{2a_m}&gt;1$，所以公式3.7又可以变为：</p>
<script type="math/tex; mode=display">e^{a_m}E=(W_c+W_e)+W_e(e^{2a_m}-1) \tag{3.8}</script><blockquote>
<p>这里的($W_c+W_e$) 就是总的代价 $W$，对于当前迭代来说它可以看做一个常量，它就是所有数据点的权重和。在第 m 个迭代时，如果我们选择了一个分类器使得错误判断的代价 $W_e$ 达到最小，那么等式3.7的右侧也就是当前迭代里的最小值了。正因为有了最小的代价，所以很显然这就保证我们选出的下一个分类器 $k_m$ 带有最小的惩罚值。</p>
</blockquote>
<h4 id="四、加权"><a href="#四、加权" class="headerlink" title="四、加权"></a>四、加权</h4><p>之前的挑选分类器的时候都是直接假定权重值 $a_m$ 是一个常数，现在把它看做一个未知数，我们要来确定它的具体的值了。看公式3.6直接对 $a_m$ 求导得：</p>
<script type="math/tex; mode=display">\frac{dE}{da_m}=-W_ce^{-a_m}+W_ee^{a_m} \tag{4.1}</script><p>直接令公式3.9等于0，再乘以 $e^{a_m}$ 可以得到：</p>
<script type="math/tex; mode=display">-W_c+W_ee^{2a_m}=0 \tag{4.2}</script><p>可以得到最优的 $a_m$ 就是：</p>
<script type="math/tex; mode=display">a_m=\frac{1}{2}ln(\frac{W_c}{W_e}) \tag{4.3}</script><p>而 $W$ 又是所有数据点权重之和，可以重写公式4.3得：</p>
<script type="math/tex; mode=display">a_m=\frac{1}{2}ln(\frac{W-We}{W_e})=\frac{1}{2}ln(\frac{1-e_m}{e_m}) \tag{4.4}</script><p>这里的 $e_m=W_e/W$，就是给定权重下，数据集的分类错误率。</p>
<h4 id="五、伪代码"><a href="#五、伪代码" class="headerlink" title="五、伪代码"></a>五、伪代码</h4><p>假设有一个数据集 T 里面的数据点为 $x_i$，这些数据点的标签 $y_i$ 是(+1,-1) 中的一个，假设所有数据点的权重初始值 $w_i^{(1)}=1$。我们想要从一系列分类器中选出 M 个分类器。执行 M 次迭代。每次迭代时，所有数据点的权重之和为 $W$，所有分类错误的数据点的权重和为 $W_e$。</p>
<p>AadBoost算法伪代码：</p>
<p>For m=1 to M<br>1.从一系列分类器中选出一个分类器错误分类权重和最小，也就是满足如下情况：</p>
<script type="math/tex; mode=display">W_e=\sum_{y_i \neq k_m(x_i)}w_i^{(m)}</script><p>2.将分类器的权重值 $a_m$ 设置为：</p>
<script type="math/tex; mode=display">a_m=\frac{1}{2}ln(\frac{1-e_m}{e_m})</script><p>这里的 $e_m=W_e/W$</p>
<p>3.为下一次迭代更新所有分类器的权重值。如果 $k_m(x_i)$ 分类错误，则设置：</p>
<script type="math/tex; mode=display">w_i^{(m+1)}=w_i^{(m)}e^{a_m}=w_i^{(m)} \sqrt{\frac{1-e_m}{e_m}}</script><p>否则设置：</p>
<script type="math/tex; mode=display">w_i^{(m+1)}=w_i^{(m)}e^{-a_m}=w_i^{(m)} \sqrt{\frac{e_m}{1-e_m}}</script><p>以上就是 AdaBoost的伪代码。</p>
<p>第一步里面的那一系列分类器可以是一个分类器族，这里面有一个分类器可使当前权重情况下的损失函数达到最小值。分类器池不必提前给出，只要是这个分类器存在的即可。如果已经给出了有限个分类器，我们只要每次测试一个即可。而这个搜索矩阵 S 可以在每次迭代的时候重复使用，只要乘以权重值 $w^{(m)}$ 所对应矩阵的转置即可，这是为了每次都能得出误分类权重 $W_e$。</p>
<p>至于这些权重值，其实是表示了权重的变化步骤，因此只有误分类才会导致权重的变化。</p>
<p>值得注意的是权重向量 $w^{(m)}$ 是迭代构造的。每次迭代可能都会导致它全部重新计算，但是还算高效也简单易实现。</p>
<p>另外，那些弱分类器的权重值会是0。如果有一个完美的分类器（$e_m=W_e/W=0$），那它的权重是无穷大，并且我们就只需要这一个分类器就好了。而一个劣质的分类器（$e_m=W_e/W=1$）的权重很显然是负无穷大，其实这样也好，我们可以每次直接对它的分类结果取反，同样我们也只需要这一个分类器即可。</p>
<h4 id="六、问题"><a href="#六、问题" class="headerlink" title="六、问题"></a>六、问题</h4><ol>
<li>假设我们为误分类分配了一个代价值 a，为正确分类分配了一个代价值 b，且 a&gt;b&gt;0，我们可以将这个代价值变形为 $a=c^d,b=c^{-d}$。这样指数损失函数 $e^{a_m},e^{-a_m}$也不影响它的通用性了。</li>
</ol>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考:"></a>参考:</h4><p>[1] Y. Freund, and R. Shapire, “A decision-theoretic generalization of on-line<br>learning and an application to boosting”, Proceedings of the Second European<br>Conference on Computational Learning Theory, 1995, pp. 23–37.</p>
<p>[2] Paul A. Viola, Michael J. Jones, “Robust Real-Time Face Detection”, ICCV<br>2001, Vol. 2, pp. 747.</p>
<p>[3] T. Hastie, R. Tibshirani, J. Friedman, The Elements of Statistical Learning,<br>Springer-Verlag, New York, 2001.</p>
<hr>
<p>THE END.</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">


    <div class="bdsharebuttonbox">
    <a href="#" class="bds_more" data-cmd="more">分享到：</a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间">QQ空间</a>
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博">新浪微博</a>
    <a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博">腾讯微博</a>
    <a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网">人人网</a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信">微信</a>
</div>
<script>
window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"share":{"bdSize":16}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>
<style>
    .bdshare_popup_box {
        border-radius: 4px;
        border: #e1e1e1 solid 1px;
    }
    .bdshare-button-style0-16 a,
    .bdshare-button-style0-16 .bds_more {
        padding-left: 20px;
        margin: 6px 10px 6px 0;
    }
    .bdshare_dialog_list a,
    .bdshare_popup_list a,
    .bdshare_popup_bottom a {
        font-family: 'Microsoft Yahei';
    }
    .bdshare_popup_top {
        display: none;
    }
    .bdshare_popup_bottom {
        height: auto;
        padding: 5px;
    }
</style>


</div>

            
    
        <a href="http://ai.wisim.me/2018/09/07/2018-09-07-Boosting/#comments" class="article-comment-link">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/09/10/2018-09-10_Bagging_RandomForest/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    Bagging 和 随机森林（Random Forest,RF）
                
            </div>
        </a>
    
    
        <a href="/2018/09/06/2018-09-06_Model_Evaluation_Selection/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">模型评估与选择</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div id="lv-container" data-id="city" data-uid=MTAyMC8zNDc5NS8xMTMzMg==></div>
</section>
    

</section>
            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2018 Wisimer<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        
    
    
    <!-- 来必力City版安装代码 -->
    <script type="text/javascript">
     (function(d, s) {
         var j, e = d.getElementsByTagName(s)[0];

         if (typeof LivereTower === 'function') { return; }

         j = d.createElement(s);
         j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
         j.async = true;

         e.parentNode.insertBefore(j, e);
     })(document, 'script');
    </script>
  <noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
  <!-- City版安装代码已完成 -->





    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>