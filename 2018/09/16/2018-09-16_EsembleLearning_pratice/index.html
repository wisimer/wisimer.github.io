<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>集成学习 实践 | XP</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="我们使用 集成学习 方法来对乳腺癌预测，这里的例子使用的数据集是 Wisconsin Breast Cancer dataset/Chapter%2003/wisc_bc_data.csv) 。这个数据集的 diagnosis 列为每一个记录的标签，有 B 和 M两个值，而其他列均是特征。下面我们来一步一步处理。">
<meta name="keywords" content="ML">
<meta property="og:type" content="article">
<meta property="og:title" content="集成学习 实践">
<meta property="og:url" content="http://ai.wisim.me/2018/09/16/2018-09-16_EsembleLearning_pratice/index.html">
<meta property="og:site_name" content="XP">
<meta property="og:description" content="我们使用 集成学习 方法来对乳腺癌预测，这里的例子使用的数据集是 Wisconsin Breast Cancer dataset/Chapter%2003/wisc_bc_data.csv) 。这个数据集的 diagnosis 列为每一个记录的标签，有 B 和 M两个值，而其他列均是特征。下面我们来一步一步处理。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://ai.wisim.me/src/imgs/1809/0916_cancer_data_set.png">
<meta property="og:image" content="http://ai.wisim.me/src/imgs/1809/0916_cancer_data_set_describe.png">
<meta property="og:image" content="http://ai.wisim.me/src/imgs/1809/0916_cancer_data_set_info.png">
<meta property="og:image" content="http://ai.wisim.me/src/imgs/1809/0916_bagging_compare.png">
<meta property="og:updated_time" content="2018-09-18T08:51:25.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="集成学习 实践">
<meta name="twitter:description" content="我们使用 集成学习 方法来对乳腺癌预测，这里的例子使用的数据集是 Wisconsin Breast Cancer dataset/Chapter%2003/wisc_bc_data.csv) 。这个数据集的 diagnosis 列为每一个记录的标签，有 B 和 M两个值，而其他列均是特征。下面我们来一步一步处理。">
<meta name="twitter:image" content="http://ai.wisim.me/src/imgs/1809/0916_cancer_data_set.png">
    

    
        <link rel="alternate" href="/" title="XP" type="application/atom+xml" />
    

    
        <link rel="icon" href="https://github.com/wisimer/wisimer.github.io/blob/master/css/images/logo.png?raw=true" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?c87f7ac22d7007b78c0d4fa544da6c44";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    


</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">XP</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">HOME</a>
                
                    <a class="main-nav-link" href="/archives">ARCHIVE</a>
                
                    <a class="main-nav-link" href="/categories">CATEGOTY</a>
                
                    <a class="main-nav-link" href="/about">ABOUT</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">HOME</a></td>
                
                    <td><a class="main-nav-link" href="/archives">ARCHIVE</a></td>
                
                    <td><a class="main-nav-link" href="/categories">CATEGOTY</a></td>
                
                    <td><a class="main-nav-link" href="/about">ABOUT</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            <section id="main"><article id="post-2018-09-16_EsembleLearning_pratice" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            集成学习 实践
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2018/09/16/2018-09-16_EsembleLearning_pratice/">
            <time datetime="2018-09-15T16:00:00.000Z" itemprop="datePublished">2018-09-16</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/ML/">ML</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/ML/">ML</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>我们使用 <code>集成学习</code> 方法来对乳腺癌预测，这里的例子使用的数据集是 <a href="https://raw.githubusercontent.com/dataspelunking/MLwR/master/Machine%20Learning%20with%20R%20(2nd%20Ed." target="_blank" rel="noopener">Wisconsin Breast Cancer dataset</a>/Chapter%2003/wisc_bc_data.csv) 。这个数据集的 <code>diagnosis</code> 列为每一个记录的标签，有 B 和 M两个值，而其他列均是特征。下面我们来一步一步处理。</p>
<a id="more"></a>
<h4 id="一、数据预处理"><a href="#一、数据预处理" class="headerlink" title="一、数据预处理"></a>一、数据预处理</h4><h5 id="1-数据导入"><a href="#1-数据导入" class="headerlink" title="1. 数据导入"></a>1. 数据导入</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.preprocessing import Imputer</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(&apos;/Users/mac/Downloads/cancer.csv&apos;)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<p>看一下输出：</p>
<p><img src="/src/imgs/1809/0916_cancer_data_set.png" alt="cancer data set"></p>
<p>看一下第一列 “id” ，对我们的训练和预测没有什么用，直接去掉即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.drop([&apos;id&apos;],axis = 1, inplace = True)</span><br></pre></td></tr></table></figure>
<p>去掉之后再看一下数据集的详细信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.describe()</span><br></pre></td></tr></table></figure>
<p><img src="/src/imgs/1809/0916_cancer_data_set_describe.png" alt="cancer data set describe"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.info()</span><br></pre></td></tr></table></figure>
<p><img src="/src/imgs/1809/0916_cancer_data_set_info.png" alt="cancer data set info"></p>
<h5 id="2-数据缺失值处理"><a href="#2-数据缺失值处理" class="headerlink" title="2. 数据缺失值处理"></a>2. 数据缺失值处理</h5><p>如果数据集中有缺失的话，我们可以使用 <code>data.replace(&#39;?&#39;,0, inplace=True)</code> 来填补缺失值。同样，我们看一下 <code>diagnosis</code> 这一列，也就是诊断结果。由于现在是字符串类型 <code>B</code> or <code>M</code>，需要变为整型，直接用 replace 替换为：<code>B(0)</code>，<code>M(1)</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.replace(&apos;B&apos;,0, inplace=True)</span><br><span class="line">data.replace(&apos;M&apos;,1, inplace=True)</span><br></pre></td></tr></table></figure>
<p>由于这里的 <code>data</code> 还是一个 <code>DataFrame &lt;class pandas.core.frame.DataFrame&gt;</code> 类型的对象，现在要转换为 Numpy 里面的数 <code>ndarray&lt;class  numpy.ndarray&gt;</code> ：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">values = data.values</span><br><span class="line">print(values)</span><br><span class="line"></span><br><span class="line"># 输出替换之后的数据</span><br><span class="line">[[ 0.      12.32    12.39    ...  0.09391  0.2827   0.06771]</span><br><span class="line"> [ 0.      10.6     18.95    ...  0.07926  0.294    0.07587]</span><br><span class="line"> [ 0.      11.04    16.83    ...  0.07431  0.2998   0.07881]</span><br><span class="line"> ...</span><br><span class="line"> [ 1.      15.28    22.41    ...  0.1226   0.3175   0.09772]</span><br><span class="line"> [ 0.      14.53    13.98    ...  0.1069   0.2606   0.0781 ]</span><br><span class="line"> [ 1.      21.37    15.1     ...  0.1966   0.273    0.08666]]</span><br></pre></td></tr></table></figure>
<p>如果是在训练集上用规则处理好数据，同时想要应用到测试集上，可以使用 <code>Imputer.fit_transform()</code>，见注[3]。</p>
<h5 id="3-数据归一化"><a href="#3-数据归一化" class="headerlink" title="3. 数据归一化"></a>3. 数据归一化</h5><p>上面缺失值处理好之后发现即使全部类型都变为整型，但是每一列的数据范围还是比较大，这样会导致特征的微小变化不会生效。下面对数据进行归一化处理，保证它们的范围都在0-1之间：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scaler = MinMaxScaler(feature_range=(0, 1))</span><br><span class="line">normalizedData = scaler.fit_transform(values)</span><br><span class="line">print(normalizedData)</span><br><span class="line"></span><br><span class="line"># 输出归一化之后的数据</span><br><span class="line">[[0.         0.25268588 0.0906324  ... 0.32271478 0.24876799 0.08310376]</span><br><span class="line"> [0.         0.17128118 0.31247886 ... 0.27237113 0.27104278 0.136626  ]</span><br><span class="line"> [0.         0.19210564 0.24078458 ... 0.25536082 0.28247585 0.15590975]</span><br><span class="line"> ...</span><br><span class="line"> [1.         0.3927777  0.42948935 ... 0.42130584 0.31736645 0.27994228]</span><br><span class="line"> [0.         0.35728146 0.14440311 ... 0.36735395 0.20520402 0.15125279]</span><br><span class="line"> [1.         0.68100715 0.18227934 ... 0.67560137 0.22964715 0.20739866]]</span><br></pre></td></tr></table></figure>
<h4 id="二、使用-sklearn-实现集成学习实例"><a href="#二、使用-sklearn-实现集成学习实例" class="headerlink" title="二、使用 sklearn 实现集成学习实例"></a>二、使用 sklearn 实现集成学习实例</h4><h5 id="1-Bagging-集成学习"><a href="#1-Bagging-集成学习" class="headerlink" title="1. Bagging 集成学习"></a>1. Bagging 集成学习</h5><p>先回顾一下 <code>Bagging</code> 算法。Bagging 是并行集成学习方法的代表。我们使用 <code>sklearn.ensemble.BaggingClassifier</code> 来实现 Bagging 集成学习：</p>
<p>文档：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.ensemble.BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=1, random_state=None, verbose=0)</span><br><span class="line"></span><br><span class="line">A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. </span><br><span class="line">Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.</span><br></pre></td></tr></table></figure>
<p>BaggingClassifier 有如下几个参数：</p>
<ul>
<li><code>base_estimator</code> ： 基学习器（可以是多个不同）</li>
<li><code>n_estimators</code> ： base_estimator 的数量</li>
<li><code>max_samples</code> ： 从数据集中取出训练每个学习器的数据最大个数</li>
<li><code>max_features</code> ： max_samples 的最大特征数</li>
<li><code>bootstrap</code> ： 取出样本后是否放回，默认 True</li>
<li><code>bootstrap_features</code> ： 样本特征取出后是否替换</li>
<li><code>oob_score</code> ： 是否使用 <code>out-of-bag</code> 方法</li>
<li><code>warm_start</code> ： 是否复用之前的模型</li>
<li><code>n_jobs</code> ： 工作 CPU 的个数</li>
<li><code>random_state</code> ： 随机种子</li>
<li><code>verbose</code> ： The verbosity level</li>
</ul>
<p>代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import model_selection</span><br><span class="line">from sklearn.ensemble import BaggingClassifier</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"># 取特征值</span><br><span class="line">X = values[:,1:31]</span><br><span class="line"># 取标签</span><br><span class="line">Y = values[:,0]</span><br><span class="line"></span><br><span class="line"># 使用 K 折交叉验证</span><br><span class="line">kfold = model_selection.KFold(n_splits=10, random_state=7)</span><br><span class="line"># 使用决策树分类</span><br><span class="line">cart = DecisionTreeClassifier()</span><br><span class="line">num_trees = 100</span><br><span class="line"># 使用 Bagging 集成学习</span><br><span class="line">model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=7)</span><br><span class="line"></span><br><span class="line"># 执行交叉验证</span><br><span class="line">results = model_selection.cross_val_score(model, X, Y, cv=kfold)</span><br><span class="line"></span><br><span class="line"># 打印 10 次验证结果的平均值</span><br><span class="line">print(results.mean())</span><br><span class="line"># 0.9561090225563911</span><br></pre></td></tr></table></figure>
<p>当然这里我们也可以横向对比一下， BaggingClassifier 的 <code>n_estimators</code> 参数取不同值的时候，模型的性能如何：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">k_range = range(10, 100, 5)</span><br><span class="line">k_scores = []</span><br><span class="line"></span><br><span class="line">for k in k_range:</span><br><span class="line">    model = BaggingClassifier(base_estimator=cart, n_estimators=k, random_state=7)</span><br><span class="line">    results = model_selection.cross_val_score(model, X, Y, cv=kfold)</span><br><span class="line">    #print(results)</span><br><span class="line">    k_scores.append(results.mean())</span><br><span class="line">    </span><br><span class="line">plt.plot(k_range, k_scores)</span><br><span class="line">plt.xlabel(&apos;Value of n_estimators for BaggingClassifier&apos;)</span><br><span class="line">plt.ylabel(&apos;Cross-Validated Accuracy&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/src/imgs/1809/0916_bagging_compare.png" alt="baggings"></p>
<p>从图中可以看到 n_estimators 不是越好，在50-60之间的时候性能较高一点点。</p>
<h5 id="2-AdaBoost-集成学习"><a href="#2-AdaBoost-集成学习" class="headerlink" title="2. AdaBoost 集成学习"></a>2. AdaBoost 集成学习</h5><p>先回顾一下 <code>Boosting</code> 算法族是一组串行序列化集成学习方法。可以将弱学习器转化为强学习器。我们这里使用 <code>sklearn.ensemble.AdaBoostClassifier</code> 来实现 Boosting 集成学习方法。</p>
<p>文档：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.ensemble.AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None)</span><br><span class="line"></span><br><span class="line">An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.</span><br></pre></td></tr></table></figure>
<p>AdaBoostClassifier 有如下几个参数：</p>
<ul>
<li><code>base_estimator</code> ： 基础模型</li>
<li><code>n_estimators</code> ： 模型数量</li>
<li><code>learning_rate</code> ： 学习速率，通过修改 learning_rate 控制每个模型的贡献值</li>
<li><code>algorithm</code> ： 具体 boosting 算法，{‘SAMME’, ‘SAMME.R’}二选一</li>
<li><code>random_state</code> ： 随机种子</li>
</ul>
<p>代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import AdaBoostClassifier</span><br><span class="line">seed = 7</span><br><span class="line">num_trees = 70</span><br><span class="line">kfold = model_selection.KFold(n_splits=10, random_state=seed)</span><br><span class="line"></span><br><span class="line"># 使用 AdaBoost 集成学习</span><br><span class="line">model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)</span><br><span class="line">results = model_selection.cross_val_score(model, X, Y, cv=kfold)</span><br><span class="line"></span><br><span class="line"># 打印 10 次验证结果的平均值</span><br><span class="line">print(results.mean())</span><br><span class="line"># 0.9649122807017545</span><br></pre></td></tr></table></figure>
<h5 id="3-基于投票法的集成学习"><a href="#3-基于投票法的集成学习" class="headerlink" title="3. 基于投票法的集成学习"></a>3. 基于投票法的集成学习</h5><p>这里将多个分类模型集合起来，对他们的分类结果采取投票法，最终得到结果。这里使用 <code>sklearn.ensemble.VotingClassifier</code> 来实现。</p>
<p>文档：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.ensemble.VotingClassifier(estimators, voting=’hard’, weights=None, n_jobs=1, flatten_transform=None)</span><br><span class="line"></span><br><span class="line">Soft Voting/Majority Rule classifier for unfitted estimators.</span><br></pre></td></tr></table></figure>
<p>VotingClassifier 有如下几个参数：</p>
<ul>
<li><code>estimators</code> ： 模型</li>
<li><code>voting</code> ： {‘hard’, ‘soft’} 二选一，hard就是单纯使用标签投票，soft则是预测可能性最大的标签。默认hard</li>
<li><code>weights</code> ： 每个方法预先的权值，默认各方法权值相同</li>
<li><code>n_jobs</code> ： 工作 CPU 数量</li>
<li><code>flatten_transform</code> ： 平滑变形，配合voting参数为soft时使用。如果voting =’soft’且flatten_transform = True，变换方法返回具有形状的矩阵（n_samples，n_classifiers * n_classes），则仅影响变换输出的形状。 如果flatten_transform = False，它将返回（n_classifiers，n_samples，n_classes）。</li>
</ul>
<p>代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from sklearn.ensemble import VotingClassifier</span><br><span class="line"></span><br><span class="line">kfold = model_selection.KFold(n_splits=10, random_state=seed)</span><br><span class="line"></span><br><span class="line"># 模型集合</span><br><span class="line">estimators = []</span><br><span class="line">model1 = LogisticRegression()</span><br><span class="line">estimators.append((&apos;logistic&apos;, model1))</span><br><span class="line">model2 = DecisionTreeClassifier()</span><br><span class="line">estimators.append((&apos;cart&apos;, model2))</span><br><span class="line">model3 = SVC()</span><br><span class="line">estimators.append((&apos;svm&apos;, model3))</span><br><span class="line"></span><br><span class="line"># Voting 作为结合策略的集成学习</span><br><span class="line">ensemble = VotingClassifier(estimators)</span><br><span class="line">results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)</span><br><span class="line">print(results.mean())</span><br><span class="line"># 0.950814536340852</span><br></pre></td></tr></table></figure>
<hr>
<p>注：</p>
<p>[1]. Imputer : sklearn 里面用于处理缺失值。</p>
<p>[2]. MinMaxScaler : sklearn 里面用于处理数据归一化。</p>
<p>[3]. <a href="https://datascience.stackexchange.com/questions/12321/difference-between-fit-and-fit-transform-in-scikit-learn-models" target="_blank" rel="noopener">fit_transform</a></p>
<hr>
<p>THE END.</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">


    <div class="bdsharebuttonbox">
    <a href="#" class="bds_more" data-cmd="more">分享到：</a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间">QQ空间</a>
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博">新浪微博</a>
    <a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博">腾讯微博</a>
    <a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网">人人网</a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信">微信</a>
</div>
<script>
window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"share":{"bdSize":16}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>
<style>
    .bdshare_popup_box {
        border-radius: 4px;
        border: #e1e1e1 solid 1px;
    }
    .bdshare-button-style0-16 a,
    .bdshare-button-style0-16 .bds_more {
        padding-left: 20px;
        margin: 6px 10px 6px 0;
    }
    .bdshare_dialog_list a,
    .bdshare_popup_list a,
    .bdshare_popup_bottom a {
        font-family: 'Microsoft Yahei';
    }
    .bdshare_popup_top {
        display: none;
    }
    .bdshare_popup_bottom {
        height: auto;
        padding: 5px;
    }
</style>


</div>

            
    
        <a href="http://ai.wisim.me/2018/09/16/2018-09-16_EsembleLearning_pratice/#comments" class="article-comment-link">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/09/17/2018-09-17_sklearn_model_selection/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    sklearn.model_selection 交叉验证
                
            </div>
        </a>
    
    
        <a href="/2018/09/14/2018-09-14_Numpy_tile/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">Numpy.tile() 函数的作用</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div id="lv-container" data-id="city" data-uid=MTAyMC8zNDc5NS8xMTMzMg==></div>
</section>
    

</section>
            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2019 Wisimer<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        
    
    
    <!-- 来必力City版安装代码 -->
    <script type="text/javascript">
     (function(d, s) {
         var j, e = d.getElementsByTagName(s)[0];

         if (typeof LivereTower === 'function') { return; }

         j = d.createElement(s);
         j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
         j.async = true;

         e.parentNode.insertBefore(j, e);
     })(document, 'script');
    </script>
  <noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
  <!-- City版安装代码已完成 -->





    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>