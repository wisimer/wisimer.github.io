<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>朴素贝叶斯分类算法实践-言论过滤器 | XP</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="一、前言以在线社区留言为例。为了不影响社区的发展，我们要屏蔽侮辱性的言论，所以要构建一个快速过滤器，如果某条留言使用了负面或者侮辱性的语言，那么就将该留言标志为内容不当。过滤这类内容是一个很常见的需求。对此问题建立两个类型：侮辱类和非侮辱类，使用1和0分别表示。">
<meta name="keywords" content="NaiveBayes">
<meta property="og:type" content="article">
<meta property="og:title" content="朴素贝叶斯分类算法实践-言论过滤器">
<meta property="og:url" content="http://ai.wisim.me/2018/05/10/2018-05-10_BayesPraticeComment/index.html">
<meta property="og:site_name" content="XP">
<meta property="og:description" content="一、前言以在线社区留言为例。为了不影响社区的发展，我们要屏蔽侮辱性的言论，所以要构建一个快速过滤器，如果某条留言使用了负面或者侮辱性的语言，那么就将该留言标志为内容不当。过滤这类内容是一个很常见的需求。对此问题建立两个类型：侮辱类和非侮辱类，使用1和0分别表示。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-07-24T06:24:34.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="朴素贝叶斯分类算法实践-言论过滤器">
<meta name="twitter:description" content="一、前言以在线社区留言为例。为了不影响社区的发展，我们要屏蔽侮辱性的言论，所以要构建一个快速过滤器，如果某条留言使用了负面或者侮辱性的语言，那么就将该留言标志为内容不当。过滤这类内容是一个很常见的需求。对此问题建立两个类型：侮辱类和非侮辱类，使用1和0分别表示。">
    

    
        <link rel="alternate" href="/" title="XP" type="application/atom+xml" />
    

    
        <link rel="icon" href="https://github.com/wisimer/wisimer.github.io/blob/master/css/images/logo.png?raw=true" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?c87f7ac22d7007b78c0d4fa544da6c44";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    


</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">XP</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">HOME</a>
                
                    <a class="main-nav-link" href="/archives">ARCHIVE</a>
                
                    <a class="main-nav-link" href="/categories/ARTS">ARTS</a>
                
                    <a class="main-nav-link" href="/categories">CATEGOTY</a>
                
                    <a class="main-nav-link" href="/about">ABOUT</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">HOME</a></td>
                
                    <td><a class="main-nav-link" href="/archives">ARCHIVE</a></td>
                
                    <td><a class="main-nav-link" href="/categories/ARTS">ARTS</a></td>
                
                    <td><a class="main-nav-link" href="/categories">CATEGOTY</a></td>
                
                    <td><a class="main-nav-link" href="/about">ABOUT</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            <section id="main"><article id="post-2018-05-10_BayesPraticeComment" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            朴素贝叶斯分类算法实践-言论过滤器
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2018/05/10/2018-05-10_BayesPraticeComment/">
            <time datetime="2018-05-09T16:00:00.000Z" itemprop="datePublished">2018-05-10</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/ML/">ML</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/NaiveBayes/">NaiveBayes</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h4 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h4><p>以在线社区留言为例。为了不影响社区的发展，我们要屏蔽侮辱性的言论，所以要构建一个快速过滤器，如果某条留言使用了负面或者侮辱性的语言，那么就将该留言标志为内容不当。过滤这类内容是一个很常见的需求。对此问题建立两个类型：侮辱类和非侮辱类，使用1和0分别表示。</p>
<a id="more"></a>
<h4 id="二、实现"><a href="#二、实现" class="headerlink" title="二、实现"></a>二、实现</h4><h5 id="1-准备工作：加载数据"><a href="#1-准备工作：加载数据" class="headerlink" title="1.准备工作：加载数据"></a>1.准备工作：加载数据</h5><p>我们把文本看成单词向量或者词条向量，也就是说将句子转换为向量。考虑出现所有文档中的单词，再决定将哪些单词纳入词汇表或者说所要的词汇集合，然后必须要将每一篇文档转换为词汇表上的向量。简单起见，我们先假设已经将本文切分完毕，存放到列表中，并对词汇向量进行分类标注。编写代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    postingList=[[<span class="string">'my'</span>, <span class="string">'dog'</span>, <span class="string">'has'</span>, <span class="string">'flea'</span>, <span class="string">'problems'</span>, <span class="string">'help'</span>, <span class="string">'please'</span>],                <span class="comment">#切分的词条</span></span><br><span class="line">                 [<span class="string">'maybe'</span>, <span class="string">'not'</span>, <span class="string">'take'</span>, <span class="string">'him'</span>, <span class="string">'to'</span>, <span class="string">'dog'</span>, <span class="string">'park'</span>, <span class="string">'stupid'</span>],</span><br><span class="line">                 [<span class="string">'my'</span>, <span class="string">'dalmation'</span>, <span class="string">'is'</span>, <span class="string">'so'</span>, <span class="string">'cute'</span>, <span class="string">'I'</span>, <span class="string">'love'</span>, <span class="string">'him'</span>],</span><br><span class="line">                 [<span class="string">'stop'</span>, <span class="string">'posting'</span>, <span class="string">'stupid'</span>, <span class="string">'worthless'</span>, <span class="string">'garbage'</span>],</span><br><span class="line">                 [<span class="string">'mr'</span>, <span class="string">'licks'</span>, <span class="string">'ate'</span>, <span class="string">'my'</span>, <span class="string">'steak'</span>, <span class="string">'how'</span>, <span class="string">'to'</span>, <span class="string">'stop'</span>, <span class="string">'him'</span>],</span><br><span class="line">                 [<span class="string">'quit'</span>, <span class="string">'buying'</span>, <span class="string">'worthless'</span>, <span class="string">'dog'</span>, <span class="string">'food'</span>, <span class="string">'stupid'</span>]]</span><br><span class="line">    classVec = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>]                                                               <span class="comment">#类别标签向量，1代表侮辱性词汇，0代表不是</span></span><br><span class="line">    <span class="keyword">return</span> postingList,classVec</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    postingLIst, classVec = loadDataSet()</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> postingLIst:</span><br><span class="line">        print(each)</span><br><span class="line">    print(classVec)</span><br></pre></td></tr></table></figure>
<p>我们已经知道贝叶斯分类属于监督学习算法，所以这里的训练数据是6个词条和对应的类别。</p>
<p>我们最终要判断某一个测试词条是否属于侮辱分类是根据之前文章<a href="http://ai.wisim.me/2018/03/27/2018-03-17_Bayes/">朴素贝叶斯分类算法原理</a>中的贝叶斯公式得到结果，也就是如下公式：</p>
<p>(1).$P(词条属于侮辱类|测试词条中每个词汇的分类) = \frac{P(词条中每个词汇的分类|词条属于侮辱类)}{P(词条中每个词汇的分类)}P(词条属于侮辱类)$</p>
<p>(2).$P(词条属于非侮辱类|测试词条中每个词汇的分类) = \frac{P(词条中每个词汇的分类|词条属于非侮辱类)}{P(词条中每个词汇的分类)}P(词条属于非侮辱类)$</p>
<p>拿（1）公式举例，P(词条属于侮辱类|测试词条中每个词汇的分类)是要求的结果，P(词条中每个词汇的分类|词条属于侮辱类)可以计算出来，P(词条中每个词汇的分类)是提前计算好的，P(词条属于侮辱类)也是已知的0.5。最终计算结果，比较两个结果大小，值更大就表示测试词条属于该类。</p>
<h5 id="2-再创建一个词汇表，并将切分好的词条转换为词条向量。"><a href="#2-再创建一个词汇表，并将切分好的词条转换为词条向量。" class="headerlink" title="2.再创建一个词汇表，并将切分好的词条转换为词条向量。"></a>2.再创建一个词汇表，并将切分好的词条转换为词条向量。</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">根据原始词条创建一个包含所有词汇且不重复的词汇表</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    vocabSet = set([])                      <span class="comment">#创建一个空的不重复列表</span></span><br><span class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:               </span><br><span class="line">        vocabSet = vocabSet | set(document) <span class="comment">#取并集</span></span><br><span class="line">    <span class="keyword">return</span> list(vocabSet)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">创建一个和词汇表相同大小的列表，标记出输入词条inputSet中的词在词汇表中的位置。如果存在就是1，不存在就是0。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWords2Vec</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line">    returnVec = [<span class="number">0</span>] * len(vocabList)                                     <span class="comment">#创建一个其中所含元素都为0的向量</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:                                                <span class="comment">#遍历每个词条</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:                                            <span class="comment">#如果词条存在于词汇表中，则置1</span></span><br><span class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>: print(<span class="string">"the word: %s is not in my Vocabulary!"</span> % word)</span><br><span class="line">    <span class="keyword">return</span> returnVec                                                    <span class="comment">#返回文档向量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#1. 加载数据</span></span><br><span class="line">    print(<span class="string">'postingList:'</span>)</span><br><span class="line">    postingList, classVec = loadDataSet()</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> postingList:</span><br><span class="line">        print(each)</span><br><span class="line">    print(<span class="string">'classVec:\n'</span>,classVec)</span><br><span class="line">    <span class="comment">#2. 创建词汇表</span></span><br><span class="line">    myVocabList = createVocabList(postingList)</span><br><span class="line">    print(<span class="string">'myVocabList:\n'</span>,myVocabList)</span><br><span class="line">    <span class="comment">#3. 创建词条向量</span></span><br><span class="line">    trainMat = []</span><br><span class="line">    <span class="keyword">for</span> postinDoc <span class="keyword">in</span> postingList:</span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">    print(<span class="string">'trainMat:\n'</span>, trainMat)</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">postingList:</span><br><span class="line">[&apos;my&apos;, &apos;dog&apos;, &apos;has&apos;, &apos;flea&apos;, &apos;problems&apos;, &apos;help&apos;, &apos;please&apos;]</span><br><span class="line">[&apos;maybe&apos;, &apos;not&apos;, &apos;take&apos;, &apos;him&apos;, &apos;to&apos;, &apos;dog&apos;, &apos;park&apos;, &apos;stupid&apos;]</span><br><span class="line">[&apos;my&apos;, &apos;dalmation&apos;, &apos;is&apos;, &apos;so&apos;, &apos;cute&apos;, &apos;I&apos;, &apos;love&apos;, &apos;him&apos;]</span><br><span class="line">[&apos;stop&apos;, &apos;posting&apos;, &apos;stupid&apos;, &apos;worthless&apos;, &apos;garbage&apos;]</span><br><span class="line">[&apos;mr&apos;, &apos;licks&apos;, &apos;ate&apos;, &apos;my&apos;, &apos;steak&apos;, &apos;how&apos;, &apos;to&apos;, &apos;stop&apos;, &apos;him&apos;]</span><br><span class="line">[&apos;quit&apos;, &apos;buying&apos;, &apos;worthless&apos;, &apos;dog&apos;, &apos;food&apos;, &apos;stupid&apos;]</span><br><span class="line">classVec:</span><br><span class="line"> [0, 1, 0, 1, 0, 1]</span><br><span class="line"></span><br><span class="line">myVocabList:</span><br><span class="line"> [&apos;food&apos;, &apos;has&apos;, &apos;to&apos;, &apos;quit&apos;, &apos;stupid&apos;, &apos;help&apos;, &apos;park&apos;, &apos;so&apos;, &apos;how&apos;, &apos;love&apos;, &apos;not&apos;, &apos;I&apos;, &apos;ate&apos;, &apos;my&apos;, &apos;licks&apos;, &apos;dalmation&apos;, &apos;flea&apos;, &apos;him&apos;, &apos;worthless&apos;, &apos;take&apos;, &apos;steak&apos;, &apos;cute&apos;, &apos;buying&apos;, &apos;stop&apos;, &apos;mr&apos;, &apos;garbage&apos;, &apos;dog&apos;, &apos;is&apos;, &apos;posting&apos;, &apos;problems&apos;, &apos;maybe&apos;, &apos;please&apos;]</span><br><span class="line"></span><br><span class="line">trainMat:</span><br><span class="line"> [[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1],</span><br><span class="line">  [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],</span><br><span class="line">  [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],</span><br><span class="line">  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0],</span><br><span class="line">  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],</span><br><span class="line">  [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]]</span><br></pre></td></tr></table></figure>
<ul>
<li>从运行结果可以看出，postingList 是原始的词条列表。</li>
<li>myVocabList 是词汇表。 myVocabList 是所有单词出现的集合，没有重复的元素。<br><code>词汇表</code> 是用来干什么的？没错，它是用来将词条 <code>向量化</code> 的，myVocabList中的一个位置上的单词在某一个原始词条中出现过一次，那么就在相应位置记作1，如果没有出现就在相应位置记作0。这样就构成了一个词条向量。</li>
<li>trainMat 是所有的词条向量组成的列表。它里面存放的是根据myVocabList向量化的词条向量。</li>
</ul>
<p>我们已经得到了词条向量。接下来，我们就可以通过词条向量训练朴素贝叶斯分类器。</p>
<h5 id="3-训练数据"><a href="#3-训练数据" class="headerlink" title="3.训练数据"></a>3.训练数据</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">根据原始词条和对应分类结果训练贝叶斯分类</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix,trainCategory)</span>:</span></span><br><span class="line">    numTrainDocs = len(trainMatrix)                            <span class="comment">#计算训练的文档数目</span></span><br><span class="line">    numWords = len(trainMatrix[<span class="number">0</span>])                             <span class="comment">#计算每篇文档的词条数</span></span><br><span class="line">    pAbusive = sum(trainCategory)/float(numTrainDocs)          <span class="comment">#文档属于侮辱类的概率</span></span><br><span class="line">    p0Num = np.zeros(numWords); p1Num = np.zeros(numWords)     <span class="comment">#创建numpy.zeros数组,词条出现数初始化为0</span></span><br><span class="line">    p0Denom = <span class="number">0.0</span>; p1Denom = <span class="number">0.0</span>                               <span class="comment">#分母初始化为0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</span><br><span class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:                              <span class="comment">#统计属于侮辱类的条件概率所需的数据，即P(w0|1),P(w1|1),P(w2|1)···</span></span><br><span class="line">            p1Num += trainMatrix[i]</span><br><span class="line">            p1Denom += sum(trainMatrix[i])</span><br><span class="line">        <span class="keyword">else</span>:                                                  <span class="comment">#统计属于非侮辱类的条件概率所需的数据，即P(w0|0),P(w1|0),P(w2|0)···</span></span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            p0Denom += sum(trainMatrix[i])</span><br><span class="line">    p1Vect = p1Num/p1Denom                                      </span><br><span class="line">    p0Vect = p0Num/p0Denom         </span><br><span class="line">    <span class="keyword">return</span> p0Vect,p1Vect,pAbusive                              <span class="comment">#返回属于非侮辱类的条件概率数组p0Vect，属于侮辱类的条件概率数组p1Vect，词条属于侮辱类的概率pAbusive</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">'postingList:'</span>)</span><br><span class="line">    postingList, classVec = loadDataSet()</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> postingList:</span><br><span class="line">        print(each)</span><br><span class="line">    print(<span class="string">'classVec:\n'</span>,classVec)</span><br><span class="line"></span><br><span class="line">    myVocabList = createVocabList(postingList)</span><br><span class="line">    print(<span class="string">'myVocabList:\n'</span>,myVocabList)</span><br><span class="line"></span><br><span class="line">    trainMat = []</span><br><span class="line">    <span class="keyword">for</span> postinDoc <span class="keyword">in</span> postingList:</span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">    print(<span class="string">'trainMat:\n'</span>, trainMat)</span><br><span class="line"></span><br><span class="line">    p0V, p1V, pAb = trainNB0(trainMat, classVec)</span><br><span class="line">    print(<span class="string">'p0V:\n'</span>, p0V)            <span class="comment">#p0V: 属于非侮辱类的条件概率数组</span></span><br><span class="line">    print(<span class="string">'p1V:\n'</span>, p1V)            <span class="comment">#p1V: 属于侮辱类的条件概率数组</span></span><br><span class="line">    print(<span class="string">'classVec:\n'</span>, classVec)  <span class="comment">#classVec: 原始词条分类结果</span></span><br><span class="line">    print(<span class="string">'pAb:\n'</span>, pAb)            <span class="comment">#pAb: 文档属于侮辱类的概率</span></span><br></pre></td></tr></table></figure>
<p>运行结果如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">p0V:</span><br><span class="line"> [0.         0.04166667 0.04166667 0.         0.         0.04166667</span><br><span class="line">  0.         0.04166667 0.04166667 0.04166667 0.         0.04166667</span><br><span class="line">  0.04166667 0.125      0.04166667 0.04166667 0.04166667 0.08333333</span><br><span class="line">  0.         0.         0.04166667 0.04166667 0.         0.04166667</span><br><span class="line">  0.04166667 0.         0.04166667 0.04166667 0.         0.04166667</span><br><span class="line">  0.         0.04166667]</span><br><span class="line">p1V:</span><br><span class="line"> [0.05263158 0.         0.05263158 0.05263158 0.15789474 0.</span><br><span class="line">  0.05263158 0.         0.         0.         0.05263158 0.</span><br><span class="line">  0.         0.         0.         0.         0.         0.05263158</span><br><span class="line">  0.10526316 0.05263158 0.         0.         0.05263158 0.05263158</span><br><span class="line">  0.         0.05263158 0.10526316 0.         0.05263158 0.</span><br><span class="line">  0.05263158 0.        ]</span><br><span class="line">classVec:</span><br><span class="line"> [0, 1, 0, 1, 0, 1]</span><br><span class="line">pAb:</span><br><span class="line"> 0.5</span><br></pre></td></tr></table></figure>
<ul>
<li>p0V存放的是每个单词属于类别0，也就是非侮辱类词汇的概率。比如p0V的倒数第6个概率，就是stupid这个单词属于非侮辱类的概率为0。</li>
<li>同理，p1V的倒数第6个概率，就是<a href="https://translate.google.cn/#en/zh-CN/stupid" target="_blank" rel="noopener">stupid</a>这个单词属于侮辱类的概率为0.15789474，也就是约等于15.79%的概率。显而易见，这个单词属于侮辱类。</li>
<li>pAb是所有侮辱类的样本占所有样本的概率，从classVec中可以看出，共有3个侮辱类，3个非侮辱类。所以侮辱类的概率是0.5。</li>
</ul>
<p>因此p0V存放的就是P(him|非侮辱类) = 0.0833、P(is|非侮辱类) = 0.0417，一直到P(dog|非侮辱类) = 0.0417，这些单词的条件概率。表示词条是非侮辱类的前提下，这些单词是属于非侮辱类的概率。</p>
<p>同理，p1V存放的就是在词条属于侮辱类的前提下，各个单词在属于侮辱类的条件概率。</p>
<p>pAb就是先验概率。</p>
<p>已经训练好分类器，接下来，使用分类器进行分类。</p>
<h5 id="4-使用贝叶斯分类器"><a href="#4-使用贝叶斯分类器" class="headerlink" title="4.使用贝叶斯分类器"></a>4.使用贝叶斯分类器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify, p0Vec, p1Vec, pClass1)</span>:</span></span><br><span class="line">    p1 = reduce(<span class="keyword">lambda</span> x,y:x*y, vec2Classify * p1Vec) * pClass1                <span class="comment">#对应元素相乘</span></span><br><span class="line">    p0 = reduce(<span class="keyword">lambda</span> x,y:x*y, vec2Classify * p0Vec) * (<span class="number">1.0</span> - pClass1)</span><br><span class="line">    print(<span class="string">'p0:'</span>,p0)</span><br><span class="line">    print(<span class="string">'p1:'</span>,p1)</span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span><span class="params">()</span>:</span></span><br><span class="line">    listOPosts,listClasses = loadDataSet()                              <span class="comment">#创建实验样本</span></span><br><span class="line">    myVocabList = createVocabList(listOPosts)                           <span class="comment">#创建词汇表</span></span><br><span class="line">    trainMat=[]</span><br><span class="line">    <span class="keyword">for</span> postinDoc <span class="keyword">in</span> listOPosts:</span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))         <span class="comment">#将实验样本向量化</span></span><br><span class="line">    p0V,p1V,pAb = trainNB0(np.array(trainMat),np.array(listClasses))    <span class="comment">#训练朴素贝叶斯分类器</span></span><br><span class="line"></span><br><span class="line">    testEntry = [<span class="string">'love'</span>, <span class="string">'my'</span>, <span class="string">'dalmation'</span>]                             <span class="comment">#测试样本1</span></span><br><span class="line">    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))          <span class="comment">#测试样本向量化</span></span><br><span class="line">    <span class="keyword">if</span> classifyNB(thisDoc,p0V,p1V,pAb):</span><br><span class="line">        print(testEntry,<span class="string">'属于侮辱类'</span>)                                     <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(testEntry,<span class="string">'属于非侮辱类'</span>)                                   <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line"></span><br><span class="line">    testEntry = [<span class="string">'stupid'</span>, <span class="string">'garbage'</span>]                                   <span class="comment">#测试样本2</span></span><br><span class="line">    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))          <span class="comment">#测试样本向量化</span></span><br><span class="line">    <span class="keyword">if</span> classifyNB(thisDoc,p0V,p1V,pAb):</span><br><span class="line">        print(testEntry,<span class="string">'属于侮辱类'</span>)                                     <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(testEntry,<span class="string">'属于非侮辱类'</span>)                                   <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   testingNB()</span><br></pre></td></tr></table></figure>
<p>这里的<code>classifyNB</code>函数还是根据下面两个公式得出的，由于只要比较大小，两个公式中 <code>P(词条中每个词汇的分类)</code> 值相同，所以只要计算比较P(词条中每个词汇的分类|词条属于侮辱类)P(词条属于侮辱类)和P(词条中每个词汇的分类|词条属于非侮辱类)P(词条属于非侮辱类)的大小。</p>
<p>(1).$P(词条属于侮辱类|测试词条中每个词汇的分类) = \frac{P(词条中每个词汇的分类|词条属于侮辱类)}{P(词条中每个词汇的分类)}P(词条属于侮辱类)$</p>
<p>(2).$P(词条属于非侮辱类|测试词条中每个词汇的分类) = \frac{P(词条中每个词汇的分类|词条属于非侮辱类)}{P(词条中每个词汇的分类)}P(词条属于非侮辱类)$</p>
<p>计算的结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">p0: 0.0</span><br><span class="line">p1: 0.0</span><br><span class="line">[&apos;love&apos;, &apos;my&apos;, &apos;dalmation&apos;] 属于非侮辱类</span><br><span class="line">p0: 0.0</span><br><span class="line">p1: 0.0</span><br><span class="line">[&apos;stupid&apos;, &apos;garbage&apos;] 属于非侮辱类</span><br></pre></td></tr></table></figure></p>
<p>但是这样写的算法无法进行分类，p0和p1的计算结果都是0，最终分类都是非侮辱类，显然结果错误。这是为什么呢？之前已经提过，利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率，即计算 p(w_{0}|1)p(w_{1}|1)p(w_{2}|1)…p(w_{n}|1)  。如果其中有一个概率值为0，那么最后的计算结果也为0。</p>
<h5 id="5-平滑处理"><a href="#5-平滑处理" class="headerlink" title="5.平滑处理"></a>5.平滑处理</h5><p>为了降低这种影响，可以将所有词的出现数初始化为1，并将分母初始化为2。这种做法就叫做拉普拉斯平滑(Laplace Smoothing)又被称为加1平滑，是比较常用的平滑方法，它就是为了解决0概率问题。</p>
<p>除此之外，另外一个遇到的问题就是下溢出，这是由于太多很小的数相乘造成的。学过数学的人都知道，两个小数相乘，越乘越小，这样就造成了下溢出。在程序中，在相应小数位置进行四舍五入，计算结果可能就变成0了。为了解决这个问题，对乘积结果取自然对数。通过求对数可以避免下溢出或者浮点数舍入导致的错误。同时，采用自然对数进行处理不会有任何损失。</p>
<p>根据上面这两种改进方法，改进之后的trainNB0方法和classifyNB方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix,trainCategory)</span>:</span></span><br><span class="line">    numTrainDocs = len(trainMatrix)                         <span class="comment">#计算训练的文档数目</span></span><br><span class="line">    numWords = len(trainMatrix[<span class="number">0</span>])                          <span class="comment">#计算每篇文档的词条数</span></span><br><span class="line">    pAbusive = sum(trainCategory)/float(numTrainDocs)       <span class="comment">#文档属于侮辱类的概率</span></span><br><span class="line">    p0Num = np.ones(numWords); p1Num = np.ones(numWords)    <span class="comment">#创建numpy.ones数组,词条出现数初始化为1，拉普拉斯平滑</span></span><br><span class="line">    p0Denom = <span class="number">2.0</span>; p1Denom = <span class="number">2.0</span>                            <span class="comment">#分母初始化为2,拉普拉斯平滑</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</span><br><span class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:                           <span class="comment">#统计属于侮辱类的条件概率所需的数据，即P(w0|1),P(w1|1),P(w2|1)···</span></span><br><span class="line">            p1Num += trainMatrix[i]</span><br><span class="line">            p1Denom += sum(trainMatrix[i])</span><br><span class="line">        <span class="keyword">else</span>:                                               <span class="comment">#统计属于非侮辱类的条件概率所需的数据，即P(w0|0),P(w1|0),P(w2|0)···</span></span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            p0Denom += sum(trainMatrix[i])</span><br><span class="line">    p1Vect = np.log(p1Num/p1Denom)                          <span class="comment">#取对数，防止下溢出         </span></span><br><span class="line">    p0Vect = np.log(p0Num/p0Denom)         </span><br><span class="line">    <span class="keyword">return</span> p0Vect,p1Vect,pAbusive                           <span class="comment">#返回属于侮辱类的条件概率数组，属于非侮辱类的条件概率数组，文档属于侮辱类的概率</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify, p0Vec, p1Vec, pClass1)</span>:</span></span><br><span class="line">    p1 = sum(vec2Classify * p1Vec) + np.log(pClass1)        <span class="comment">#对应元素相乘。logA * B = logA + logB，所以这里加上log(pClass1)</span></span><br><span class="line">    p0 = sum(vec2Classify * p0Vec) + np.log(<span class="number">1.0</span> - pClass1)</span><br><span class="line">    print(<span class="string">'p0:'</span>,p0)</span><br><span class="line">    print(<span class="string">'p1:'</span>,p1)</span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>最终计算出来的分类结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">p0: -7.694848072384611</span><br><span class="line">p1: -9.826714493730215</span><br><span class="line">[&apos;love&apos;, &apos;my&apos;, &apos;dalmation&apos;] 属于非侮辱类</span><br><span class="line">p0: -7.20934025660291</span><br><span class="line">p1: -4.702750514326955</span><br><span class="line">[&apos;stupid&apos;, &apos;garbage&apos;] 属于侮辱类</span><br></pre></td></tr></table></figure>
<hr>
<p>参考：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/28719332" target="_blank" rel="noopener">Python3《机器学习实战》学习笔记（四）：朴素贝叶斯基础篇之言论过滤器</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/28720393" target="_blank" rel="noopener">Python3《机器学习实战》学习笔记（五）：朴素贝叶斯实战篇之新浪新闻分类</a></li>
</ol>
<p>附：</p>
<p><a href="/raw/code/BayesClassify/BayesClassify_CommentClassify.ipynb.ipynb">code</a></p>
<hr>
<p>THE END.</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">


    <div class="bdsharebuttonbox">
    <a href="#" class="bds_more" data-cmd="more">分享到：</a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间">QQ空间</a>
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博">新浪微博</a>
    <a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博">腾讯微博</a>
    <a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网">人人网</a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信">微信</a>
</div>
<script>
window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"share":{"bdSize":16}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>
<style>
    .bdshare_popup_box {
        border-radius: 4px;
        border: #e1e1e1 solid 1px;
    }
    .bdshare-button-style0-16 a,
    .bdshare-button-style0-16 .bds_more {
        padding-left: 20px;
        margin: 6px 10px 6px 0;
    }
    .bdshare_dialog_list a,
    .bdshare_popup_list a,
    .bdshare_popup_bottom a {
        font-family: 'Microsoft Yahei';
    }
    .bdshare_popup_top {
        display: none;
    }
    .bdshare_popup_bottom {
        height: auto;
        padding: 5px;
    }
</style>


</div>

            
    
        <a href="http://ai.wisim.me/2018/05/10/2018-05-10_BayesPraticeComment/#comments" class="article-comment-link">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/05/14/2018-05-14_BayesPraticeEmail/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    朴素贝叶斯分类算法实践-垃圾邮件过滤器
                
            </div>
        </a>
    
    
        <a href="/2018/05/03/2018-05-03_Matplotlib/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">Matplotlib</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div id="lv-container" data-id="city" data-uid=MTAyMC8zNDc5NS8xMTMzMg==></div>
</section>
    

</section>
            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2018 Wisimer<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        
    
    
    <!-- 来必力City版安装代码 -->
    <script type="text/javascript">
     (function(d, s) {
         var j, e = d.getElementsByTagName(s)[0];

         if (typeof LivereTower === 'function') { return; }

         j = d.createElement(s);
         j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
         j.async = true;

         e.parentNode.insertBefore(j, e);
     })(document, 'script');
    </script>
  <noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
  <!-- City版安装代码已完成 -->





    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>